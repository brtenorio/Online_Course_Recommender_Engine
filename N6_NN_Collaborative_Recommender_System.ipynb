{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96bf8be2-d336-4d67-8c00-157efc0a7ecd"
      },
      "source": [
        "# **Course Rating Prediction using Neural Networks**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d92ce8bc-666f-4f7e-b9cf-902444784b0b"
      },
      "source": [
        "In our previous Notebook, we have crafted several types of user and item feature vectors. With these explicit features vectors, we can perform machine learning tasks such as calculating the similarities among users or items, finding nearest neighbors, and using dot-product to estimate a rating value. \n",
        "\n",
        "The main advantage of using these explicit features is they are highly interpretable and yield very good performance as well. The main disadvantage is we need to spend quite some effort to build and store them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5566430-e1c3-484e-b4c8-2bae4b6cb851"
      },
      "source": [
        "Nonetheless, it is possible to predict a rating without building explicit feature vectors beforehand using Neural Networks.\n",
        "\n",
        "The Non-negative Matrix Factorization decomposes the **user-item interaction matrix** into **user matrix** and **item matrix**, which contain the **latent features** of users and items and we can simply dot-product them to get an estimated rating.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e59271b9-823d-4a6e-9880-d998da9c4659"
      },
      "source": [
        "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/nmf.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b4e3e5b-5c3b-40c2-9a52-99ac04a7034d"
      },
      "source": [
        "In addition to NMF, neural networks can also be used to extract the latent user and item features. In fact,  neural networks are very good at learning patterns from data and are widely used to extract latent features.  When training neural networks, it gradually captures and stores the features within its hidden layers as weight matrices and can be extracted to represent the original data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the workflow, we first extract two embedding matrices out of the neural network, and aggregate them to be a single interaction feature vector as input data `X`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35f65caf-6524-4366-839a-2b9e368c478b"
      },
      "source": [
        "## Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "280579ff-ce45-4943-9553-09626580ce60"
      },
      "source": [
        "After completing this lab you will be able to:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd5c8fa5-0b8c-403a-b71f-4f406466d407"
      },
      "source": [
        "* Use `tensorflow` to train neural networks to extract the user and item latent features from the hidden's layers  \n",
        "* Predict course ratings with trained neural networks\n",
        "* Build classification models to predict rating modes using the combined embedding vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d94ad96a-fee1-4a74-9e7e-708ca31aecc9"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1736e3bb-1934-4ea8-bbc5-619b897ae128"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "import math \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cEF6xhPzWKkN"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Dot, Embedding, Activation, Add\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1a620ef3-2572-424f-8076-36dd54c8fb2e"
      },
      "outputs": [],
      "source": [
        "# also set a random state\n",
        "rs = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea62446e-bcf7-45b4-92c4-378c22155105"
      },
      "source": [
        "### Load and processing rating dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e1cf70b7-5df0-4250-a25f-fd4a9a39f3fc",
        "outputId": "80f36475-36f8-48a1-f687-af8fe908b2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(233306, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1889878</td>\n",
              "      <td>CC0101EN</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1342067</td>\n",
              "      <td>CL0101EN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1990814</td>\n",
              "      <td>ML0120ENv3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>380098</td>\n",
              "      <td>BD0211EN</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>779563</td>\n",
              "      <td>DS0101EN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      user        item  rating\n",
              "0  1889878    CC0101EN       5\n",
              "1  1342067    CL0101EN       3\n",
              "2  1990814  ML0120ENv3       5\n",
              "3   380098    BD0211EN       5\n",
              "4   779563    DS0101EN       3"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rating_df = pd.read_csv('ratings.csv')\n",
        "print(rating_df.shape)\n",
        "rating_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ratings distribute similarly across the 3 categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.histplot(rating_df['rating'])\n",
        "ax = plt.gca()\n",
        "ax.set_xlim([2, 6])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52581f87-e478-49ea-a0f2-98e2137a4ba1"
      },
      "source": [
        "Next, let's figure out how many unique users and items, their total numbers will determine the sizes of one-hot encoding vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b7c4207-33e0-4239-a989-8e92bde23b0a",
        "outputId": "88bdecc4-b4f9-4a04-a97c-605db0490278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are total `33901` of users and `126` items\n"
          ]
        }
      ],
      "source": [
        "num_users = len(rating_df['user'].unique())\n",
        "num_items = len(rating_df['item'].unique())\n",
        "print(f\"There are total `{num_users}` of users and `{num_items}` items\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b25bffc-468d-4c67-a7e8-0a9a8000bd0e"
      },
      "source": [
        "It means our each user can be represented as a `33901 x 1` one-hot vector and each item can be represented as `126 x 1` one-hot vector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04ec5cd5-af22-409d-88cb-6ffcda24f786"
      },
      "source": [
        "The goal is to create a neural network structure that can take the user and item one-hot vectors as inputs and outputs a rating estimation or the probability of interaction.\n",
        "\n",
        "While training and updating the weights in the neural network, its hidden layers should be able to capture the pattern or features for each user and item. Based on this idea, we can design a simple neural network architecture like the following:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04f75abc-3588-4f42-8ac3-440e1a5a49e7"
      },
      "source": [
        "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/embedding_feature_vector.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c89e44c6-93b8-4ae8-bc3a-d0b56b85f371"
      },
      "source": [
        "The network inputs are two one-hot encoding vectors, the blue one is for the user and the green one is for the item. Then on top of them, we added two embedding layers. Here embedding means embedding the one-hot encoding vector into a latent feature space. The embedding layer is a fully-connected layer that outputs the embedding feature vectors. For example, the user embedding layer takes `33901 x 1` one-hot vector as input and outputs a `16 x 1` embedding vector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbe4512a-1b1f-4ec1-9a11-cc2c36f3fbd5"
      },
      "source": [
        "The embedding layer outputs two embedding vectors, which are similar to Non-negative matrix factorization. Then we could simply dot the product the user and item embedding vector to output a rating estimation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2af40bfe-221c-40ef-acaa-dab3dca061fa"
      },
      "source": [
        "#### Implementing the recommender neural network using tensorflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd95dafc-9efd-452f-9554-b3e060d0170e"
      },
      "source": [
        "Before training the Neuro Network, we need to process the original rating dataset a little bit by converting the actual user ids and item ids into integer indices for `tensorflow` to creating the one-hot encoding vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0db5dec8-e041-4351-acf8-709fcde52db1"
      },
      "outputs": [],
      "source": [
        "def process_dataset(raw_data):\n",
        "    \"\"\"\n",
        "        Preprocesses the raw dataset by encoding user and item IDs to indices.\n",
        "\n",
        "        Args:\n",
        "        - raw_data (DataFrame): Raw dataset containing user, item, and rating information.\n",
        "\n",
        "        Returns:\n",
        "        - encoded_data (DataFrame): Processed dataset with user and item IDs encoded as indices.\n",
        "        - user_idx2id_dict (dict): Dictionary mapping user indices to original user IDs.\n",
        "        - course_idx2id_dict (dict): Dictionary mapping item indices to original item IDs.\n",
        "    \"\"\"\n",
        "\n",
        "    encoded_data = raw_data.copy() # Make a copy of the raw dataset to avoid modifying the original data.\n",
        "\n",
        "    # Mapping user ids to indices\n",
        "    user_list = encoded_data[\"user\"].unique().tolist() # Get unique user IDs from the dataset.\n",
        "    user_id2idx_dict = {x: i for i, x in enumerate(user_list)} # Create a dictionary mapping user IDs to indices.\n",
        "    user_idx2id_dict = {i: x for i, x in enumerate(user_list)} # Create a dictionary mapping user indices back to original user IDs.\n",
        "\n",
        "    # Mapping course ids to indices\n",
        "    course_list = encoded_data[\"item\"].unique().tolist() # Get unique item (course) IDs from the dataset.\n",
        "    course_id2idx_dict = {x: i for i, x in enumerate(course_list)} # Create a dictionary mapping item IDs to indices.\n",
        "    course_idx2id_dict = {i: x for i, x in enumerate(course_list)} # Create a dictionary mapping item indices back to original item IDs.\n",
        "\n",
        "    # Convert original user ids to idx\n",
        "    encoded_data[\"user\"] = encoded_data[\"user\"].map(user_id2idx_dict)\n",
        "    # Convert original course ids to idx\n",
        "    encoded_data[\"item\"] = encoded_data[\"item\"].map(course_id2idx_dict)\n",
        "    # Convert rating to int\n",
        "    encoded_data[\"rating\"] = encoded_data[\"rating\"].values.astype(\"int\")\n",
        "\n",
        "    return encoded_data, user_idx2id_dict, course_idx2id_dict # Return the processed dataset and dictionaries mapping indices to original IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "086e139a-f541-40f2-a523-20e6150cc196"
      },
      "outputs": [],
      "source": [
        "# Process the raw dataset using the process_dataset function\n",
        "# The function returns three values: encoded_data, user_idx2id_dict, and course_idx2id_dict\n",
        "# encoded_data: Processed dataset with user and item IDs encoded as indices\n",
        "# user_idx2id_dict: Dictionary mapping user indices to original user IDs\n",
        "# course_idx2id_dict: Dictionary mapping item indices to original item IDs\n",
        "encoded_data, user_idx2id_dict, course_idx2id_dict = process_dataset(rating_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4e003ca8-7c54-47d7-b410-b9e5607e90af",
        "outputId": "16bea794-9161-45de-9aca-1c04f225e307"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user  item  rating\n",
              "0     0     0       5\n",
              "1     1     1       3\n",
              "2     2     2       5\n",
              "3     3     3       5\n",
              "4     4     4       3"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the training variables\n",
        "x = encoded_data[['user','item']]\n",
        "y = encoded_data['rating'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we can split the encoded dataset into training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define train, validate, and test sets\n",
        "x_tr, x_test, y_tr, y_test = train_test_split(x, y, test_size=0.1, random_state = rs)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_tr, y_tr, test_size=0.1, random_state = rs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we take a look at the training input data, it is simply just a list of user indices and item indices, which is a dense format of one-hot encoding vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>88268</th>\n",
              "      <td>15384</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138794</th>\n",
              "      <td>12873</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166242</th>\n",
              "      <td>3421</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185232</th>\n",
              "      <td>23775</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131484</th>\n",
              "      <td>9182</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         user  item\n",
              "88268   15384    21\n",
              "138794  12873    99\n",
              "166242   3421     7\n",
              "185232  23775    23\n",
              "131484   9182    99"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train.to_numpy()\n",
        "x_test = x_test.to_numpy()\n",
        "x_val = x_val.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0c98f31-e2c9-42cd-9159-a906a150cb0e"
      },
      "source": [
        "Then we can choose a small embedding vector size to be **50** and create a Neural Network model to be trained.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are total `33901` of users and `126` items\n"
          ]
        }
      ],
      "source": [
        "num_users = len(rating_df['user'].unique())\n",
        "num_items = len(rating_df['item'].unique())\n",
        "print(f\"There are total `{num_users}` of users and `{num_items}` items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95d56d1a-f596-40cb-9882-70ac5d556af2",
        "outputId": "d6531801-2d72-4e41-a58d-481f52cd1983"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_layer_us… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,017,030</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_layer_it… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,780</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_layer_… │\n",
              "│                     │                   │            │ embedding_layer_… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bias_layer_user     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,901</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ bias_layer_user[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bias_layer_item     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ bias_layer_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_layer_us… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │  \u001b[38;5;34m1,017,030\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_layer_it… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │      \u001b[38;5;34m3,780\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ embedding_layer_… │\n",
              "│                     │                   │            │ embedding_layer_… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bias_layer_user     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │     \u001b[38;5;34m33,901\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dot[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ bias_layer_user[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bias_layer_item     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m126\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ bias_layer_item[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,054,837</span> (4.02 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,054,837\u001b[0m (4.02 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,054,837</span> (4.02 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,054,837\u001b[0m (4.02 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embedding_size = 30\n",
        "\n",
        "# Define input layers for two sets of data\n",
        "input_user = Input(shape=(1,))\n",
        "input_item = Input(shape=(1,))\n",
        "\n",
        "# Define embedding layer for user\n",
        "embedding_layer_user = Embedding(input_dim=num_users, output_dim=embedding_size,\n",
        "                                 embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "                                 embeddings_initializer=\"he_normal\",\n",
        "                                 name='embedding_layer_user'\n",
        "                                 )(input_user)\n",
        "\n",
        "# Bias is applied per user, hence output_dim is set to 1\n",
        "bias_layer_user = Embedding(input_dim=num_users, output_dim=1, \n",
        "                            embeddings_initializer=\"zeros\",\n",
        "                            name='bias_layer_user')(input_user)\n",
        "\n",
        "# Define embedding layer for item\n",
        "embedding_layer_item = Embedding(input_dim=num_items, output_dim=embedding_size,\n",
        "                                 embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "                                 embeddings_initializer=\"he_normal\",\n",
        "                                 name='embedding_layer_item'\n",
        "                                 )(input_item)\n",
        "\n",
        "# Bias is applied per item, hence output_dim is set to 1\n",
        "bias_layer_item = Embedding(input_dim=num_items, output_dim=1, \n",
        "                            embeddings_initializer=\"zeros\",\n",
        "                            name='bias_layer_item')(input_item)\n",
        "\n",
        "# Perform dot product of the two embedded layers\n",
        "dot_product = Dot(axes=2)([embedding_layer_user, embedding_layer_item])\n",
        "\n",
        "# Add bias to dot\n",
        "add_bias = dot_product + bias_layer_user + bias_layer_item\n",
        "\n",
        "# Add ReLu\n",
        "add_ReLu = Activation('relu')(add_bias)\n",
        "\n",
        "# Create the Keras model\n",
        "model = Model(inputs=[input_user, input_item], outputs=add_ReLu)\n",
        "\n",
        "opt = keras.optimizers.AdamW(learning_rate=0.003)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['root_mean_squared_error'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "1Fi-zAd4BPlK",
        "outputId": "df870049-15e3-458d-ae7b-94de6725b215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - loss: 5.5985 - root_mean_squared_error: 2.2664 - val_loss: 0.7645 - val_root_mean_squared_error: 0.8678\n",
            "Epoch 2/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.7373 - root_mean_squared_error: 0.8523 - val_loss: 0.7196 - val_root_mean_squared_error: 0.8427\n",
            "Epoch 3/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 5ms/step - loss: 0.7000 - root_mean_squared_error: 0.8317 - val_loss: 0.6946 - val_root_mean_squared_error: 0.8296\n",
            "Epoch 4/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.6845 - root_mean_squared_error: 0.8238 - val_loss: 0.6831 - val_root_mean_squared_error: 0.8234\n",
            "Epoch 5/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 5ms/step - loss: 0.6810 - root_mean_squared_error: 0.8224 - val_loss: 0.6805 - val_root_mean_squared_error: 0.8219\n",
            "Epoch 6/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.6776 - root_mean_squared_error: 0.8203 - val_loss: 0.6794 - val_root_mean_squared_error: 0.8214\n",
            "Epoch 7/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - loss: 0.6775 - root_mean_squared_error: 0.8203 - val_loss: 0.6778 - val_root_mean_squared_error: 0.8204\n",
            "Epoch 8/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.6792 - root_mean_squared_error: 0.8214 - val_loss: 0.6775 - val_root_mean_squared_error: 0.8203\n",
            "Epoch 9/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 5ms/step - loss: 0.6761 - root_mean_squared_error: 0.8196 - val_loss: 0.6772 - val_root_mean_squared_error: 0.8201\n",
            "Epoch 10/10\n",
            "\u001b[1m5906/5906\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.6787 - root_mean_squared_error: 0.8212 - val_loss: 0.6770 - val_root_mean_squared_error: 0.8201\n"
          ]
        }
      ],
      "source": [
        "run_hist = model.fit(x=[x_train[:,0], x_train[:,1]], y=y_train, epochs=10, batch_size=32, shuffle=True, validation_data=([x_val[:,0], x_val[:,1]],y_val)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "feTuSLBdEELk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'RMSE over iterations')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAIOCAYAAABOJNWwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABwWElEQVR4nO3deVwVZf//8fcBBQQEdxZZxC33DdJELTWD1EjbRDPcMPW2MtMWvd3Noqzb9Js/TA01y8rbMusuM6m0NDWXtEy5TXNBFCQpwTRBYX5/cHPyCCog42F5PR+PeeC5zjUznzny4HM+c10zYzEMwxAAAAAAADCFg70DAAAAAACgPKPwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwRrmzbNkyWSwW7dy5096hlAtHjx6VxWLRsmXLrG1btmzR9OnTdebMGbvFdb04unbtqq5du970mAAAJSsvr+ctlSpVko+Pj/r376+DBw/m69+1a1dZLBbVr19fhmHke//bb7+1buvy3CZJ33//ve677z4FBATI2dlZXl5e6tixo8aPH1/gPgpa6tWrV5KHb1dDhgzJdzwvvvii1qxZY5d4ChPHxo0bZbFYtHHjxpseE3AtFN4ArsnHx0dbt25V7969rW1btmzRjBkzSkXhfbU4YmNjFRsbe/ODAgCYYunSpdq6dau+/PJLPf744/rkk0/UuXNn/fHHH/n6Vq1aVUeOHNHXX3+d770lS5bIw8MjX/tnn32m0NBQZWRkaPbs2Vq/fr3mzZunTp06aeXKlfn6169fX1u3bs23fPTRRyVzwKXAlClT8h1PaS+827Vrp61bt6pdu3Y3PyjgGirZOwAA9vfXX3/JxcVFFosl33vOzs667bbbbkoc58+fl6ura4lsq1mzZiWyHQBA6dCiRQuFhIRIyh1xzs7O1rRp07RmzRoNHTrUpm9AQICqVq2qJUuW6M4777S2nz17VqtWrdLAgQO1ePFim3Vmz56toKAgffHFF6pU6e+vyP3799fs2bPzxVOlSpWblh/N9Ndff6lKlSoFvtegQYObEkN2drYuXbokZ2fnG96Wh4dHufh/QfnDiDcqrM2bN+vOO+9U1apV5erqqtDQUH322Wc2fc6fP6+nn35aQUFBcnFxUY0aNRQSEqL33nvP2ufw4cPq37+/fH19rdPS7rzzTu3Zs+e6MXzyySfq2LGjXF1dVbVqVd11113aunWr9f01a9bIYrHoq6++yrfuggULZLFY9NNPP1nbdu7cqXvvvVc1atSQi4uL2rZtq3//+9826+VN2Vu/fr2GDRum2rVry9XVVZmZmQXGeOVU8+nTp+uZZ56RJAUFBVmn1l0+pWvlypXq2LGj3Nzc5O7urvDwcO3evdtmu0OGDJG7u7v27t2rsLAwVa1a1frlKD4+Xn369JGfn59cXFzUsGFDjRw5UqdPn7auf704Cppq/vvvv2v06NGqW7eunJycVL9+fU2aNCnfsVssFj3++ON6++231bRpU7m6uqp169b69NNPbfr99ttvGjFihPz9/eXs7KzatWurU6dO+vLLLwv8LAEAJSevCD916lSB7w8bNkyrV6+2mRX1/vvvS8otpq+UlpamWrVq2RTdeRwcSvYrc2HyUdu2bdWlS5d862ZnZ6tu3bq6//77rW1ZWVmaNWuWmjRpYs1HQ4cO1W+//Wazbr169XTPPfdo9erVatu2rVxcXDRjxoyrxnnlVHOLxaJz587prbfesubdy3NtSkqKRo4cKT8/Pzk5OSkoKEgzZszQpUuXrH3yvlfMnj1bs2bNUlBQkJydnbVhwwZduHBB48ePV5s2beTp6akaNWqoY8eO+vjjj23iulYcV5tqfr3vXFLudwuLxaJ9+/ZpwIAB8vT0lJeXl4YNG6b09HSbvqtWrVKHDh3k6ekpV1dX1a9fX8OGDbvqZwkw4o0K6ZtvvtFdd92lVq1aKS4uTs7OzoqNjVVERITee+89RUZGSpLGjRunt99+W7NmzVLbtm117tw5/fzzz0pLS7Nuq1evXsrOztbs2bMVEBCg06dPa8uWLdedhv3uu+9q4MCBCgsL03vvvafMzEzNnj1bXbt21VdffaXOnTvrnnvuUZ06dbR06VKbM/ZSbgHdrl07tWrVSpK0YcMG3X333erQoYPeeOMNeXp66v3331dkZKTOnz+vIUOG2Kw/bNgw9e7dW2+//bbOnTunypUrF+qzGz58uH7//Xe9/vrrWr16tXx8fCT9PcL84osvavLkyRo6dKgmT56srKwsvfLKK+rSpYu2b99uMxKdlZWle++9VyNHjtSECROsifnXX39Vx44dNXz4cHl6euro0aOaM2eOOnfurL1796py5crXjeNKFy5cULdu3fTrr79qxowZatWqlTZt2qSYmBjt2bMn30mXzz77TDt27NDMmTPl7u6u2bNn67777tOBAwdUv359SVJUVJR++OEHvfDCC2rcuLHOnDmjH374web3AwBgjiNHjkiSGjduXOD7/fv311NPPaX33ntP//jHPyRJcXFxevDBBwucat6xY0e9+eabGjNmjAYOHKh27dpdNzdeXlDmcXBwuGahXth8NHToUD355JM6ePCgGjVqZF1//fr1OnnypHWUPycnR3369NGmTZv07LPPKjQ0VMeOHdO0adPUtWtX7dy502ZE+4cfflBCQoImT56soKAgubm5XfMYL7d161Z1795d3bp105QpUyTJ+lmmpKSoffv2cnBw0NSpU9WgQQNt3bpVs2bN0tGjR7V06VKbbf3f//2fGjdurFdffVUeHh5q1KiRMjMz9fvvv+vpp59W3bp1lZWVpS+//FL333+/li5dqkGDBl03joIU5jvX5R544AFFRkYqOjpae/fu1cSJEyXlXqaQt//IyEhFRkZq+vTpcnFx0bFjxwq8tAGwMoByZunSpYYkY8eOHVftc9tttxl16tQxzp49a227dOmS0aJFC8PPz8/IyckxDMMwWrRoYfTt2/eq2zl9+rQhyZg7d26RYszOzjZ8fX2Nli1bGtnZ2db2s2fPGnXq1DFCQ0OtbePGjTOqVKlinDlzxtq2f/9+Q5Lx+uuvW9uaNGlitG3b1rh48aLNvu655x7Dx8fHup+8z2fQoEGFivXIkSOGJGPp0qXWtldeecWQZBw5csSmb2JiolGpUiXjiSeesGk/e/as4e3tbfTr18/aNnjwYEOSsWTJkmvuPycnx7h48aJx7NgxQ5Lx8ccfXzcOwzCMO+64w7jjjjusr9944w1DkvHvf//bpt/LL79sSDLWr19vbZNkeHl5GRkZGda2lJQUw8HBwYiJibG2ubu7G2PHjr1m/ACAG5OXt7Zt22ZcvHjROHv2rLFu3TrD29vbuP322/PlvTvuuMNo3ry5YRi5uSYkJMQwDMPYt2+fIcnYuHGjsWPHjny57fTp00bnzp0NSYYko3LlykZoaKgRExNj830hbx95/a5coqOjr3k8hc1Hp0+fNpycnIx//vOfNv369etneHl5WY/7vffeMyQZH374oU2/vGOMjY21tgUGBhqOjo7GgQMHrhljnsGDBxuBgYE2bW5ubsbgwYPz9R05cqTh7u5uHDt2zKb91VdfNSQZ+/btMwzj7+8VDRo0MLKysq65/0uXLhkXL140oqOjjbZt2xYqjg0bNhiSjA0bNhiGUbTvXNOmTTMkGbNnz7bZ5ujRow0XFxfr98O8Y7r8uxlwPUw1R4Vz7tw5ff/993rwwQfl7u5ubXd0dFRUVJSSkpJ04MABSVL79u31+eefa8KECdq4caP++usvm23VqFFDDRo00CuvvKI5c+Zo9+7dysnJuW4MBw4c0MmTJxUVFWVzVtzd3V0PPPCAtm3bpvPnz0vKHZn+66+/bG7ssnTpUjk7O+vhhx+WJB06dEj//e9/NXDgQEm5Z+Dzll69eik5Odl6THkeeOCBonxshfLFF1/o0qVLGjRokE0MLi4uuuOOOwq8w2hBcaSmpmrUqFHy9/dXpUqVVLlyZQUGBkqSEhISihXb119/LTc3Nz344IM27XkzAa6czt+tWzdVrVrV+trLy0t16tTRsWPHrG3t27fXsmXLNGvWLG3btk0XL14sVmwAgOu77bbbVLlyZVWtWlV33323qlevro8//rjAqeF5hg0bpp07d2rv3r2Ki4tTgwYNdPvttxfYt2bNmtq0aZN27Nihl156SX369NEvv/yiiRMnqmXLljaXO0m51z/v2LEj35I3Ans1hc1HNWvWVEREhN566y3rd4s//vhDH3/8sQYNGmQ97k8//VTVqlVTRESETe5t06aNvL298+XeVq1aXXWWwI349NNP1a1bN/n6+trE0bNnT0m5sw0vd++99xY4o2DVqlXq1KmT3N3drd8B4uLiip3/i/Kd6/LYLteqVStduHBBqampkqRbb71VktSvXz/9+9//1okTJ4oVGyoWCm9UOH/88YcMw7BOTb6cr6+vJFmnCv/f//2fnnvuOa1Zs0bdunVTjRo11LdvX+vjS/Kuvw4PD9fs2bPVrl071a5dW2PGjNHZs2evGkPe9q8WQ05OjvUurc2bN9ett95qnaKVnZ2td955R3369FGNGjUk/X1929NPP63KlSvbLKNHj5akfF8YCtr3jcqL49Zbb80Xx8qVK/PF4Orqmm9qWE5OjsLCwrR69Wo9++yz+uqrr7R9+3Zt27ZNkvKd/CistLQ0eXt757uBXJ06dVSpUqV808Nr1qyZbxvOzs42+1+5cqUGDx6sN998Ux07dlSNGjU0aNAgpaSkFCtGAMDVLV++XDt27NDXX3+tkSNHKiEhQQMGDLjmOrfffrsaNWqkhQsX6u2339awYcMKvJHo5UJCQvTcc89p1apVOnnypJ566ikdPXo03w3WXFxcFBISkm/JO1F8NUXJR8OGDdOJEycUHx8vSdZp0pdfPnbq1CmdOXNGTk5O+XJvSkrKTcn/eXH85z//yRdD8+bNJRXue8jq1avVr18/1a1bV++88462bt2qHTt2aNiwYbpw4UKx4irKd648V34HyLvpW953gNtvv11r1qyxDjb4+fmpRYsWNvcAAq7ENd6ocKpXry4HBwclJyfne+/kyZOSpFq1akmS3NzcNGPGDM2YMUOnTp2yjn5HRETov//9ryQpMDBQcXFxkqRffvlF//73vzV9+nRlZWXpjTfeKDCGvD/oV4vBwcFB1atXt7YNHTpUo0ePVkJCgg4fPqzk5GSbO7jmxTtx4kSbm61c7pZbbrF5fb0vHsWRF8cHH3xw3S8eV4vh559/1o8//qhly5Zp8ODB1vZDhw7dUGw1a9bU999/L8MwbPabmpqqS5cuWWMvilq1amnu3LmaO3euEhMT9cknn2jChAlKTU3VunXrbiheAICtpk2bWm+o1q1bN2VnZ+vNN9/UBx98kG/0+HJ59xyxWCw2eaUwKleurGnTpum1117Tzz//fEPx5ylKPgoPD5evr6+WLl2q8PBwLV26VB06dLC5n0mtWrVUs2bNq+ady2dvSebk/7w4WrVqpRdeeKHA9/MGN64VxzvvvKOgoCCtXLnS5v2r3QC2MIr6nauw+vTpoz59+igzM1Pbtm1TTEyMHn74YdWrV08dO3YsdrwovxjxRoXj5uamDh06aPXq1Tajlzk5OXrnnXfk5+dX4BQsLy8vDRkyRAMGDNCBAwfyTUuScm/wMnnyZLVs2VI//PDDVWO45ZZbVLduXb377rsyDMPafu7cOX344YfWu27mGTBggFxcXLRs2TItW7ZMdevWVVhYmM32GjVqpB9//LHAs+8hISH5Eu+NuPLMb57w8HBVqlRJv/7661XjuJ68RHvlI0UWLlxY6DgKcuedd+rPP//M98zP5cuXW9+/EQEBAXr88cd11113XfP/HgBQMmbPnq3q1atr6tSp17zMa/DgwYqIiNAzzzyjunXrXrVfQYWZ9PclTlcWjsVVlHyUdxncmjVrtGnTJu3cuTPfnbPvuecepaWlKTs7u8C8e+WJ9xt15eyvy+P4+eef1aBBgwLjKMznZ7FY5OTkZFN0p6Sk5Lur+bXiuFJRv3MVlbOzs+644w69/PLLkpTvKS5AHka8UW59/fXXOnr0aL72Xr16KSYmRnfddZe6deump59+Wk5OToqNjdXPP/+s9957z/oHv0OHDrrnnnvUqlUrVa9eXQkJCXr77betf6R/+uknPf7443rooYfUqFEjOTk56euvv9ZPP/2kCRMmXDU2BwcHzZ49WwMHDtQ999yjkSNHKjMzU6+88orOnDmjl156yaZ/tWrVdN9992nZsmU6c+aMnn766Xx3TF24cKF69uyp8PBwDRkyRHXr1tXvv/+uhIQE/fDDD1q1atWNf6j/07JlS0nSvHnzNHjwYFWuXFm33HKL6tWrp5kzZ2rSpEk6fPiw9Rq8U6dOafv27dYZBNfSpEkTNWjQQBMmTJBhGKpRo4b+85//WKfZFSaOgk4yDBo0SP/v//0/DR48WEePHlXLli21efNmvfjii+rVq5d69OhRpM8gPT1d3bp108MPP6wmTZqoatWq2rFjh9atW3fVWQcAgJJTvXp1TZw4Uc8++6zeffddPfLIIwX28/X1zVfkFiQ8PFx+fn6KiIhQkyZNlJOToz179uhf//qX3N3d9eSTT9r0/+uvv6yXQV3pWs+RLmo+GjZsmF5++WU9/PDDqlKlivXJK3n69++vFStWqFevXnryySfVvn17Va5cWUlJSdqwYYP69Omj++6777rHX1gtW7bUxo0b9Z///Ec+Pj6qWrWqbrnlFs2cOVPx8fEKDQ3VmDFjdMstt+jChQs6evSo1q5dqzfeeEN+fn7X3Hbeo85Gjx6tBx98UMePH9fzzz8vHx8f62V+14vjSkX9zlUYU6dOVVJSku688075+fnpzJkzmjdvnipXrqw77rijyNtDBWHPO7sBZsi7++nVlrw7YG/atMno3r274ebmZlSpUsW47bbbjP/85z8225owYYIREhJiVK9e3XB2djbq169vPPXUU8bp06cNwzCMU6dOGUOGDDGaNGliuLm5Ge7u7karVq2M1157zbh06dJ1Y12zZo3RoUMHw8XFxXBzczPuvPNO47vvviuw7/r1663H8MsvvxTY58cffzT69etn1KlTx6hcubLh7e1tdO/e3XjjjTfyfT7Xuuv75Qq6q7lhGMbEiRMNX19fw8HBwebuoXnH1a1bN8PDw8NwdnY2AgMDjQcffND48ssvrX0GDx5suLm5FbjP/fv3G3fddZdRtWpVo3r16sZDDz1kJCYmGpKMadOmFSqOK+9qbhiGkZaWZowaNcrw8fExKlWqZAQGBhoTJ040Lly4YNNPkvHYY4/liyswMNB6B9ULFy4Yo0aNMlq1amV4eHgYVapUMW655RZj2rRpxrlz567+gQIAiuRaeeuvv/4yAgICjEaNGlnz7uV3Nb+agu5qvnLlSuPhhx82GjVqZLi7uxuVK1c2AgICjKioKGP//v0261/rruaS8t1p/UqFzUd5QkNDDUnGwIEDC3z/4sWLxquvvmq0bt3acHFxMdzd3Y0mTZoYI0eONA4ePGjtFxgYaPTu3fuasV2uoLua79mzx+jUqZPh6upqSLLJtb/99psxZswYIygoyKhcubJRo0YNIzg42Jg0aZLx559/Gobx9/eKV155pcB9vvTSS0a9evUMZ2dno2nTpsbixYutdxsvTBxX3tU8T2G+c+Xt57fffrNpz/sdzPsO+emnnxo9e/Y06tatazg5ORl16tQxevXqZWzatKkQnyoqKothXDbnAgAAAAAAlCiu8QYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKtk7gJKSk5OjkydPqmrVqrJYLPYOBwBQwRmGobNnz8rX11cODpznLgnkegBAaVPYfF9uCu+TJ0/K39/f3mEAAGDj+PHj8vPzs3cY5QK5HgBQWl0v35ebwrtq1aqScg/Yw8PDztEAACq6jIwM+fv7W/MTbhy5HgBQ2hQ235ebwjtvypmHhwfJGABQajAluuSQ6wEApdX18j0XnQEAAAAAYCIKbwAAAAAATEThDQAAAACAicrNNd4AcC3Z2dm6ePGivcNAOVO5cmU5OjraOwwAKPfI47CXksr1FN4AyjXDMJSSkqIzZ87YOxSUU9WqVZO3tzc3UQMAE5DHURqURK6n8AZQruUl6zp16sjV1ZXiCCXGMAydP39eqampkiQfHx87RwQA5Q95HPZUkrmewhtAuZWdnW1N1jVr1rR3OCiHqlSpIklKTU1VnTp1mHYOACWIPI7SoKRyPTdXA1Bu5V0L5urqaudIUJ7l/X5x7SEAlCzyOEqLksj1FN4Ayj2mpcFM/H4BgLn4Owt7K4nfQQpvAAAAAABMROENABVA165dNXbsWHuHAQAAiolcXrZReANAKWKxWK65DBkypFjbXb16tZ5//vkbim3IkCHq27fvDW0DAIDyrrTn8rw4KlWqpICAAP3jH//QH3/8YdOvXr16slgsev/99/Nto3nz5rJYLFq2bJm1bffu3brnnntUp04dubi4qF69eoqMjNTp06clSUePHr3q57Ft27YbOqaygruaA0ApkpycbP33ypUrNXXqVB04cMDalndnzTwXL15U5cqVr7vdGjVqlFyQAADgqkp7Lr/77ru1dOlSXbp0Sfv379ewYcN05swZvffeezb9/P39tXTpUvXv39/atm3bNqWkpMjNzc3alpqaqh49eigiIkJffPGFqlWrpiNHjuiTTz7R+fPnbbb55Zdfqnnz5jZtFeWO9Yx4A0BhJCVJGzbk/jSRt7e3dfH09JTFYrG+vnDhgqpVq6Z///vf6tq1q1xcXPTOO+8oLS1NAwYMkJ+fn1xdXdWyZct8yfPK6Wn16tXTiy++qGHDhqlq1aoKCAjQokWLbij2b775Ru3bt5ezs7N8fHw0YcIEXbp0yfr+Bx98oJYtW6pKlSqqWbOmevTooXPnzkmSNm7cqPbt28vNzU3VqlVTp06ddOzYsRuKBwAAG+RySZKzs7O8vb3l5+ensLAwRUZGav369fn6DRw4UN98842OHz9ubVuyZIkGDhyoSpX+Hr/dsmWLMjIy9Oabb6pt27YKCgpS9+7dNXfuXAUEBNhss2bNmjafj7e3d6FOOpQHFN4AcD1xcVJgoNS9e+7PuDi7hvPcc89pzJgxSkhIUHh4uC5cuKDg4GB9+umn+vnnnzVixAhFRUXp+++/v+Z2/vWvfykkJES7d+/W6NGj9Y9//EP//e9/ixXTiRMn1KtXL91666368ccftWDBAsXFxWnWrFmScs/+DxgwQMOGDVNCQoI2btyo+++/X4Zh6NKlS+rbt6/uuOMO/fTTT9q6datGjBjBXWwBACWHXF6gw4cPa926dQUWv15eXgoPD9dbb70lSTp//rxWrlypYcOG2fTz9vbWpUuX9NFHH8kwjELvu6JhqnlBkpKkgwelRo0kPz97RwPAnpKSpBEjpJyc3Nc5OdLIkVJ4uN3+PowdO1b333+/TdvTTz9t/fcTTzyhdevWadWqVerQocNVt9OrVy+NHj1aUu4XgNdee00bN25UkyZNihxTbGys/P39NX/+fFksFjVp0kQnT57Uc889p6lTpyo5OVmXLl3S/fffr8DAQElSy5YtJUm///670tPTdc8996hBgwaSpKZNmxY5BqBIyPVAxUEut/Hpp5/K3d1d2dnZunDhgiRpzpw5BfYdNmyYxo8fr0mTJumDDz5QgwYN1KZNG5s+t912m/75z3/q4Ycf1qhRo9S+fXt1795dgwYNkpeXl03f0NBQOTjYjv2mp6fL0dHxqvGWF4x4X6mUnQ0DYGcHD/6dqPNkZ0uHDtknHkkhISE2r7Ozs/XCCy+oVatWqlmzptzd3bV+/XolJiZeczutWrWy/jtvGlxqamqxYkpISFDHjh1tRqk7deqkP//8U0lJSWrdurXuvPNOtWzZUg899JAWL15svZFLjRo1NGTIEIWHhysiIkLz5s2zuT4OKHHkeqBiIZfb6Natm/bs2aPvv/9eTzzxhMLDw/XEE08U2Ld37976888/9e2332rJkiX5RrvzvPDCC0pJSdEbb7yhZs2a6Y033lCTJk20d+9em34rV67Unj17bJaKUHRLFN62rnY2zOTrQACUYo0aSVecmZWjo9SwoX3ikWxuaCLlTjN77bXX9Oyzz+rrr7/Wnj17FB4erqysrGtu58ppZRaLRTlXfjEpJMMw8k0Nz5tuZrFY5OjoqPj4eH3++edq1qyZXn/9dd1yyy06cuSIJGnp0qXaunWrQkNDtXLlSjVu3LjC3OUUNxm5Hqh4yOX59t2wYUO1atVK//d//6fMzEzNmDGjwL6VKlVSVFSUpk2bpu+//14DBw686nZr1qyphx56SP/617+UkJAgX19fvfrqqzZ9/P391bBhQ5uloqDwvlwpPBsGwM78/KRFi3ITtJT7c+HCUjU1ddOmTerTp48eeeQRtW7dWvXr19fBgwdvagzNmjXTli1bbK7t2rJli6pWraq6detKyv0y0KlTJ82YMUO7d++Wk5OTPvroI2v/tm3bauLEidqyZYtatGihd99996YeAyoIcj1Q8ZDLr2natGl69dVXdfLkyQLfHzZsmL755hv16dNH1atXL9Q2nZyc1KBBA+tNVME13rbyzoZdnpDtfDYMQCkQHZ17HdihQ7l/D0pRopakhg0b6sMPP9SWLVtUvXp1zZkzRykpKaZcJ52enq49e/bYtNWoUUOjR4/W3Llz9cQTT+jxxx/XgQMHNG3aNI0bN04ODg76/vvv9dVXXyksLEx16tTR999/r99++01NmzbVkSNHtGjRIt17773y9fXVgQMH9Msvv2jQoEElHj9ArgcqKHL5VXXt2lXNmzfXiy++qPnz5+d7v2nTpjp9+rRcXV0LXP/TTz/V+++/r/79+6tx48YyDEP/+c9/tHbtWi1dutSmb1pamlJSUmzaqlWrJhcXl5I7oFKKEe/LlYGzYQDsxM9P6tq1VP49mDJlitq1a6fw8HB17dpV3t7e6tu3ryn72rhxo9q2bWuzTJ06VXXr1tXatWu1fft2tW7dWqNGjVJ0dLQmT54sSfLw8NC3336rXr16qXHjxpo8ebL+9a9/qWfPnnJ1ddV///tfPfDAA2rcuLFGjBihxx9/XCNHjjTlGJB7M7ygoCC5uLgoODhYmzZtumb/FStWqHXr1nJ1dZWPj4+GDh2qtLS0Avu+//77slgs+X4Hp0+fLovFYrN4e3uX1CEVHrkeqLjI5Vc1btw4LV682ObRYZerWbNmvueP52nWrJlcXV01fvx4tWnTRrfddpv+/e9/680331RUVJRN3x49esjHx8dmWbNmTUkfTqlkMcrJPd8zMjLk6emp9PR0eXh43NjGkpJK7dkwAIV34cIFHTlyxFpgAGa42u9ZiealErRy5UpFRUUpNjZWnTp10sKFC/Xmm29q//79+Z63KkmbN2/WHXfcoddee00RERE6ceKERo0apUaNGtlcKiBJx44dU6dOnVS/fn3VqFHD5svU9OnT9cEHH+jLL7+0tjk6Oqp27dqFjp1cD1Qs5HGUFtf6XSxsbmLEuyCl+GwYAAA3Ys6cOYqOjtbw4cPVtGlTzZ07V/7+/lqwYEGB/bdt26Z69eppzJgxCgoKUufOnTVy5Ejt3LnTpl92drYGDhyoGTNmqH79+gVuq1KlSvL29rYuRSm6Sxy5HgBwE1F4AwBQQWRlZWnXrl0KCwuzaQ8LC9OWLVsKXCc0NFRJSUlau3atDMPQqVOn9MEHH6h37942/WbOnKnatWsrOjr6qvs/ePCgfH19FRQUpP79++vw4cM3flAAAJQB3FwNAIAK4vTp08rOzpaXl5dNu5eXV76b3eQJDQ3VihUrFBkZqQsXLujSpUu699579frrr1v7fPfdd4qLi8t3473LdejQQcuXL1fjxo116tQpzZo1S6Ghodq3b59q1qxZ4DqZmZnKzMy0vs7IyCjC0QIAUHow4g0AQAVT0DPXr2zLs3//fo0ZM0ZTp07Vrl27tG7dOh05ckSjRo2SJJ09e1aPPPKIFi9erFq1al11nz179tQDDzygli1bqkePHvrss88kSW+99dZV14mJiZGnp6d18ff3L+qhAgBQKjDiDQBABVGrVi05OjrmG91OTU3NNwqeJyYmRp06ddIzzzwjSWrVqpXc3NzUpUsXzZo1S6dOndLRo0cVERFhXSfnf4/qqlSpkg4cOKAGDRrk266bm5tatmx5zefUTpw4UePGjbO+zsjIoPgGAJRJjHgDAFBBODk5KTg4WPHx8Tbt8fHxCg0NLXCd8+fPy8HB9uuC4/8exWUYhpo0aaK9e/dqz5491uXee+9Vt27dtGfPnqsWypmZmUpISJCPj89V43V2dpaHh4fNAgBAWcSINwAAFci4ceMUFRWlkJAQdezYUYsWLVJiYqJ16vjEiRN14sQJLV++XJIUERGhRx99VAsWLFB4eLiSk5M1duxYtW/fXr6+vpKkFi1a2OyjWrVq+dqffvppRUREKCAgQKmpqZo1a5YyMjI0ePDgm3DUAADYF4U3AAAVSGRkpNLS0jRz5kwlJyerRYsWWrt2rQIDAyVJycnJSkxMtPYfMmSIzp49q/nz52v8+PGqVq2aunfvrpdffrlI+01KStKAAQN0+vRp1a5dW7fddpu2bdtm3S8AAOWZxTAMw95BlITCPrgcQMVx4cIFHTlyREFBQXJxcbF3OCinrvZ7Rl4qeXymQMVCHkdpca3fxcLmJq7xBoByqGvXrho7dqz1db169TR37txrrmOxWLRmzZob3ndJbQcAgIqMXF6+UHgDQCkSERGhHj16FPje1q1bZbFY9MMPPxR5uzt27NCIESNuNDwb06dPV5s2bfK1Jycnq2fPniW6rystW7bMeh0xAAClCbm8cJYtWyaLxWJdvLy8FBERoX379tn0GzJkiCwWi/VeJJcbPXq0LBaLhgwZYm1LTU3VyJEjFRAQIGdnZ3l7eys8PFxbt2619qlXr57NvvOWl156ybTjpfAGgFIkOjpaX3/9tY4dO5bvvSVLlqhNmzZq165dkbdbu3Ztubq6lkSI1+Xt7S1nZ+ebsi8AAEobcnnheXh4KDk5WSdPntRnn32mc+fOqXfv3srKyrLp5+/vr/fff19//fWXte3ChQt67733FBAQYNP3gQce0I8//qi33npLv/zyiz755BN17dpVv//+u02/vHudXL488cQTph0rhTcAFEJSkrRhQ+5PM91zzz2qU6eOli1bZtN+/vx5rVy5UtHR0UpLS9OAAQPk5+cnV1dXtWzZUu+99941t3vl9LSDBw/q9ttvl4uLi5o1a5bv8VKS9Nxzz6lx48ZydXVV/fr1NWXKFF28eFFS7lnqGTNm6Mcff7SeJc6L+crpaXv37lX37t1VpUoV1axZUyNGjNCff/5pfX/IkCHq27evXn31Vfn4+KhmzZp67LHHrPsqjsTERPXp00fu7u7y8PBQv379dOrUKev7P/74o7p166aqVavKw8NDwcHB2rlzpyTp2LFjioiIUPXq1eXm5qbmzZtr7dq1xY4FAFA6kMtLXy63WCzy9vaWj4+PQkJC9NRTT+nYsWM6cOCATb927dopICBAq1evtratXr1a/v7+atu2rbXtzJkz2rx5s15++WV169ZNgYGBat++vSZOnKjevXvbbLNq1ary9va2Wdzc3K4Z742g8AaA64iLkwIDpe7dc3/GxZm3r0qVKmnQoEFatmyZLr/35apVq5SVlaWBAwfqwoULCg4O1qeffqqff/5ZI0aMUFRUlL7//vtC7SMnJ0f333+/HB0dtW3bNr3xxht67rnn8vWrWrWqli1bpv3792vevHlavHixXnvtNUm5d8YeP368mjdvbj1LHBkZmW8b58+f1913363q1atrx44dWrVqlb788ks9/vjjNv02bNigX3/9VRs2bNBbb72lZcuW5fvCUliGYahv3776/fff9c033yg+Pl6//vqrTXwDBw6Un5+fduzYoV27dmnChAmqXLmyJOmxxx5TZmamvv32W+3du1cvv/yy3N3dixULAKB0IJeX/lx+5swZvfvuu5JkzcmXGzp0qJYuXWp9vWTJEg0bNsymj7u7u9zd3bVmzRplZmYWet83hVFOpKenG5KM9PR0e4cCoJT466+/jP379xt//fVXsbdx/LhhODgYhvT34uiY226WhIQEQ5Lx9ddfW9tuv/12Y8CAAVddp1evXsb48eOtr++44w7jySeftL4ODAw0XnvtNcMwDOOLL74wHB0djeOXHcTnn39uSDI++uijq+5j9uzZRnBwsPX1tGnTjNatW+frd/l2Fi1aZFSvXt34888/re9/9tlnhoODg5GSkmIYhmEMHjzYCAwMNC5dumTt89BDDxmRkZFXjWXp0qWGp6dnge+tX7/ecHR0NBITE61t+/btMyQZ27dvNwzDMKpWrWosW7aswPVbtmxpTJ8+/ar7vtLVfs/ISyWPzxSoWEoijxsGufxypS2XSzLc3NwMV1dXQ5Ihybj33ntt+g0ePNjo06eP8dtvvxnOzs7GkSNHjKNHjxouLi7Gb7/9ZvTp08cYPHiwtf8HH3xgVK9e3XBxcTFCQ0ONiRMnGj/++KPNNgMDAw0nJyfDzc3NZtmwYUOBsV7rd7GwuYkRbwC4hoMHpZwc27bsbOnQIfP22aRJE4WGhmrJkiWSpF9//VWbNm2yntXNzs7WCy+8oFatWqlmzZpyd3fX+vXrbZ69fC0JCQkKCAiQn5+fta1jx475+n3wwQfq3LmzvL295e7urilTphR6H5fvq3Xr1jZTtzp16qScnBybaWTNmzeXo6Oj9bWPj49SU1OLtK/L9+nv7y9/f39rW7NmzVStWjUlJCRIksaNG6fhw4erR48eeumll/Trr79a+44ZM0azZs1Sp06dNG3aNP3000/FigMAUDqQy0tvLq9atar27NmjXbt26Y033lCDBg30xhtvFNi3Vq1a6t27t9566y0tXbpUvXv3Vq1atfL1e+CBB3Ty5El98sknCg8P18aNG9WuXbt8o+/PPPOM9uzZY7N06NChMB9JsVB4A8A1NGokOVzxl9LRUWrY0Nz9RkdH68MPP1RGRoaWLl2qwMBA3XnnnZKkf/3rX3rttdf07LPP6uuvv9aePXsUHh6e70YkV2NcNu0tj8VisXm9bds29e/fXz179tSnn36q3bt3a9KkSYXex+X7unLbBe3zyillFotFOVd+S7rBfV7ePn36dO3bt0+9e/fW119/rWbNmumjjz6SJA0fPlyHDx9WVFSU9u7dq5CQEL3++uvFigUAYH/k8tKbyx0cHNSwYUM1adJEI0eOVFRUVIHT3fMMGzZMy5Yt01tvvZVvmvnlXFxcdNddd2nq1KnasmWLhgwZomnTptn0qVWrlho2bGizVKlS5Zrx3ggKbwC4Bj8/adGi3AQt5f5cuDC33Uz9+vWTo6Oj3n33Xb311lsaOnSoNblt2rRJffr00SOPPKLWrVurfv36OnjwYKG33axZMyUmJurkyZPWtssfsSFJ3333nQIDAzVp0iSFhISoUaNG+e7O6uTkpOzs7Ovua8+ePTp37pzNth0cHNS4ceNCx1wUecd3/Phxa9v+/fuVnp6upk2bWtsaN26sp556SuvXr9f9999vc92Yv7+/Ro0apdWrV2v8+PFavHixKbECAMxHLi87ufypp57Sjz/+aD0ZfqW7775bWVlZysrKUnh4eKG326xZM5v47YHCGwCuIzpaOno0906oR4/mvjabu7u7IiMj9c9//lMnT560eT5lw4YNFR8fry1btighIUEjR45USkpKobfdo0cP3XLLLRo0aJB+/PFHbdq0SZMmTbLp07BhQyUmJur999/Xr7/+qv/7v//LlwTr1aunI0eOaM+ePTp9+nSBNzEZOHCgXFxcNHjwYP3888/asGGDnnjiCUVFRcnLy6toH8oVsrOz800R279/v3r06KFWrVpp4MCB+uGHH7R9+3YNGjRId9xxh0JCQvTXX3/p8ccf18aNG3Xs2DF999132rFjh7UoHzt2rL744gsdOXJEP/zwg77++mubgh0AUPaQy0tnLr+Sh4eHhg8frmnTphU4qu/o6KiEhAQlJCTYTGvPk5aWpu7du+udd97RTz/9pCNHjmjVqlWaPXu2+vTpY9P37NmzSklJsVkyMjJK9HguR+ENAIXg5yd17Wr+2fHLRUdH648//lCPHj1snlE5ZcoUtWvXTuHh4eratau8vb3Vt2/fQm/XwcFBH330kTIzM9W+fXsNHz5cL7zwgk2fPn366KmnntLjjz+uNm3aaMuWLZoyZYpNnwceeEB33323unXrptq1axf4GBRXV1d98cUX+v3333XrrbfqwQcf1J133qn58+cX7cMowJ9//qm2bdvaLL169bI+AqV69eq6/fbb1aNHD9WvX18rV66UlJu009LSNGjQIDVu3Fj9+vVTz549NWPGDEm5Bf1jjz2mpk2b6u6779Ytt9yi2NjYG44XAGBf5PLSl8sL8uSTTyohIUGrVq0q8H0PDw95eHgU+J67u7s6dOig1157TbfffrtatGihKVOm6NFHH80X79SpU+Xj42OzPPvssyV+PHksRkGnEsqgjIwMeXp6Kj09/ar/EQAqlgsXLujIkSMKCgqSi4uLvcNBOXW13zPyUsnjMwUqFvI4Sotr/S4WNjcx4g0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbQLmXk5Nj7xBQjvH7BQDm4u8s7K0kfgcrlUAcAFAqOTk5ycHBQSdPnlTt2rXl5OQki8Vi77BQThiGoaysLP32229ycHCQk5OTvUMCgHKFPA57K8lcT+ENoNxycHBQUFCQkpOTdfLkSXuHg3LK1dVVAQEBcnBgEhkAlCTyOEqLksj1FN4AyjUnJycFBATo0qVLys7Otnc4KGccHR1VqVIlRmAAwCTkcdhbSeV6Cm8A5Z7FYlHlypVVuXJle4cCAACKiDyO8oB5cQAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADBRsQrv2NhYBQUFycXFRcHBwdq0adNV+w4ZMkQWiyXf0rx5c2ufxYsXq0uXLqpevbqqV6+uHj16aPv27cUJDQAA4LqSkqQNG3J/AgBgtiIX3itXrtTYsWM1adIk7d69W126dFHPnj2VmJhYYP958+YpOTnZuhw/flw1atTQQw89ZO2zceNGDRgwQBs2bNDWrVsVEBCgsLAwnThxovhHBgAAUIC4OCkwUOrePfdnXJy9IwIAlHcWwzCMoqzQoUMHtWvXTgsWLLC2NW3aVH379lVMTMx111+zZo3uv/9+HTlyRIGBgQX2yc7OVvXq1TV//nwNGjSoUHFlZGTI09NT6enp8vDwKNzBAABgEvJSySuJzzQpKbfYzsn5u83RUTp6VPLzK5k4AQAVR2FzU5FGvLOysrRr1y6FhYXZtIeFhWnLli2F2kZcXJx69Ohx1aJbks6fP6+LFy+qRo0aV+2TmZmpjIwMmwUAAOBaDh60LbolKTtbOnTIPvEAACqGIhXep0+fVnZ2try8vGzavby8lJKSct31k5OT9fnnn2v48OHX7DdhwgTVrVtXPXr0uGqfmJgYeXp6Whd/f//CHQQAAKiwGjWSHK749uPoKDVsaJ94AAAVQ7FurmaxWGxeG4aRr60gy5YtU7Vq1dS3b9+r9pk9e7bee+89rV69Wi4uLlftN3HiRKWnp1uX48ePFzr+6+GGKwAAlE9+ftKiRbnFtpT7c+FCppkDAMxVqSida9WqJUdHx3yj26mpqflGwa9kGIaWLFmiqKgoOTk5Fdjn1Vdf1Ysvvqgvv/xSrVq1uub2nJ2d5ezsXJTwCyUuThoxIncamoNDbnKOji7x3QAAADuJjpbCw3OnlzdsSNENADBfkUa8nZycFBwcrPj4eJv2+Ph4hYaGXnPdb775RocOHVL0VarYV155Rc8//7zWrVunkJCQooRVYpKS/i66pdyfI0cy8g0AQHnj5yd17UrRDQC4OYo04i1J48aNU1RUlEJCQtSxY0ctWrRIiYmJGjVqlKTcKeAnTpzQ8uXLbdaLi4tThw4d1KJFi3zbnD17tqZMmaJ3331X9erVs46ou7u7y93dvTjHVSzXuuEKiRkAAAAAUBxFLrwjIyOVlpammTNnKjk5WS1atNDatWutdylPTk7O90zv9PR0ffjhh5o3b16B24yNjVVWVpYefPBBm/Zp06Zp+vTpRQ2x2PJuuHLlI0a44QoAAAAAoLiK/Bzv0qqknpcaF5c7vTw7++8brnCNNwCgqHiOd8njMwUAlDaFzU1FHvEu77jhCgAAAACgJFF4F8DPj4IbAAAAAFAyivUcbwAAAAAAUDgU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAABVMbGysgoKC5OLiouDgYG3atOma/VesWKHWrVvL1dVVPj4+Gjp0qNLS0grs+/7778tisahv3743vF8AAMoLCm8AACqQlStXauzYsZo0aZJ2796tLl26qGfPnkpMTCyw/+bNmzVo0CBFR0dr3759WrVqlXbs2KHhw4fn63vs2DE9/fTT6tKlyw3vFwCA8oTCGwCACmTOnDmKjo7W8OHD1bRpU82dO1f+/v5asGBBgf23bdumevXqacyYMQoKClLnzp01cuRI7dy506Zfdna2Bg4cqBkzZqh+/fo3vF8AAMoTCm8AACqIrKws7dq1S2FhYTbtYWFh2rJlS4HrhIaGKikpSWvXrpVhGDp16pQ++OAD9e7d26bfzJkzVbt2bUVHR5fIfgEAKE8q2TsAAABwc5w+fVrZ2dny8vKyaffy8lJKSkqB64SGhmrFihWKjIzUhQsXdOnSJd177716/fXXrX2+++47xcXFac+ePSW2X0nKzMxUZmam9XVGRsb1DhEAgFKJEW8AACoYi8Vi89owjHxtefbv368xY8Zo6tSp2rVrl9atW6cjR45o1KhRkqSzZ8/qkUce0eLFi1WrVq0S268kxcTEyNPT07r4+/sX5vAAACh1GPEGAKCCqFWrlhwdHfONMqempuYbjc4TExOjTp066ZlnnpEktWrVSm5uburSpYtmzZqlU6dO6ejRo4qIiLCuk5OTI0mqVKmSDhw4IH9//yLvV5ImTpyocePGWV9nZGRQfAMAyiRGvAEAqCCcnJwUHBys+Ph4m/b4+HiFhoYWuM758+fl4GD7dcHR0VFS7oh1kyZNtHfvXu3Zs8e63HvvverWrZv27Nkjf3//Yu1XkpydneXh4WGzAABQFjHiDQBABTJu3DhFRUUpJCREHTt21KJFi5SYmGidOj5x4kSdOHFCy5cvlyRFRETo0Ucf1YIFCxQeHq7k5GSNHTtW7du3l6+vrySpRYsWNvuoVq1avvbr7RcAgPKMwhsAgAokMjJSaWlpmjlzppKTk9WiRQutXbtWgYGBkqTk5GSbZ2sPGTJEZ8+e1fz58zV+/HhVq1ZN3bt318svv1yi+wUAoDyzGIZh2DuIkpCRkSFPT0+lp6czFQ0AYHfkpZLHZwoAKG0Km5u4xhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJioWIV3bGysgoKC5OLiouDgYG3atOmqfYcMGSKLxZJvad68ubXPvn379MADD6hevXqyWCyaO3duccICAAAAAKDUKXLhvXLlSo0dO1aTJk3S7t271aVLF/Xs2VOJiYkF9p83b56Sk5Oty/Hjx1WjRg099NBD1j7nz59X/fr19dJLL8nb27v4RwMAAAAAQClT5MJ7zpw5io6O1vDhw9W0aVPNnTtX/v7+WrBgQYH9PT095e3tbV127typP/74Q0OHDrX2ufXWW/XKK6+of//+cnZ2Lv7RAAAAAABQyhSp8M7KytKuXbsUFhZm0x4WFqYtW7YUahtxcXHq0aOHAgMDi7JrAAAAAADKpEpF6Xz69GllZ2fLy8vLpt3Ly0spKSnXXT85OVmff/653n333aJFWYDMzExlZmZaX2dkZNzwNgEAAAAAKGnFurmaxWKxeW0YRr62gixbtkzVqlVT3759i7NbGzExMfL09LQu/v7+N7xNAAAAAABKWpEK71q1asnR0THf6HZqamq+UfArGYahJUuWKCoqSk5OTkWP9AoTJ05Uenq6dTl+/PgNbxMAAAAAgJJWpMLbyclJwcHBio+Pt2mPj49XaGjoNdf95ptvdOjQIUVHRxc9ygI4OzvLw8PDZgEAAAAAoLQp0jXekjRu3DhFRUUpJCREHTt21KJFi5SYmKhRo0ZJyh2JPnHihJYvX26zXlxcnDp06KAWLVrk22ZWVpb2799v/feJEye0Z88eubu7q2HDhsU5LgAAAAAASoUiF96RkZFKS0vTzJkzlZycrBYtWmjt2rXWu5QnJyfne6Z3enq6PvzwQ82bN6/AbZ48eVJt27a1vn711Vf16quv6o477tDGjRuLGiIAAAAAAKWGxTAMw95BlISMjAx5enoqPT2daecAALsjL5U8PlMAQGlT2NxUrLuaAwAAAACAwqHwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AACqY2NhYBQUFycXFRcHBwdq0adM1+69YsUKtW7eWq6urfHx8NHToUKWlpVnfX716tUJCQlStWjW5ubmpTZs2evvtt222MX36dFksFpvF29vblOMDAKC0ofAGAKACWblypcaOHatJkyZp9+7d6tKli3r27KnExMQC+2/evFmDBg1SdHS09u3bp1WrVmnHjh0aPny4tU+NGjU0adIkbd26VT/99JOGDh2qoUOH6osvvrDZVvPmzZWcnGxd9u7da+qxAgBQWlB4AwBQgcyZM0fR0dEaPny4mjZtqrlz58rf318LFiwosP+2bdtUr149jRkzRkFBQercubNGjhypnTt3Wvt07dpV9913n5o2baoGDRroySefVKtWrbR582abbVWqVEne3t7WpXbt2qYeKwAApQWFNwAAFURWVpZ27dqlsLAwm/awsDBt2bKlwHVCQ0OVlJSktWvXyjAMnTp1Sh988IF69+5dYH/DMPTVV1/pwIEDuv32223eO3jwoHx9fRUUFKT+/fvr8OHDJXNgAACUcpXsHQAAALg5Tp8+rezsbHl5edm0e3l5KSUlpcB1QkNDtWLFCkVGRurChQu6dOmS7r33Xr3++us2/dLT01W3bl1lZmbK0dFRsbGxuuuuu6zvd+jQQcuXL1fjxo116tQpzZo1S6Ghodq3b59q1qxZ4L4zMzOVmZlpfZ2RkVHcQwcAwK4Y8QYAoIKxWCw2rw3DyNeWZ//+/RozZoymTp2qXbt2ad26dTpy5IhGjRpl069q1aras2ePduzYoRdeeEHjxo3Txo0bre/37NlTDzzwgFq2bKkePXros88+kyS99dZbV40zJiZGnp6e1sXf37+YRwwAgH0x4g0AQAVRq1YtOTo65hvdTk1NzTcKnicmJkadOnXSM888I0lq1aqV3Nzc1KVLF82aNUs+Pj6SJAcHBzVs2FCS1KZNGyUkJCgmJkZdu3YtcLtubm5q2bKlDh48eNV4J06cqHHjxllfZ2RkUHwDAMokRrwBAKggnJycFBwcrPj4eJv2+Ph4hYaGFrjO+fPn5eBg+3XB0dFRUu5I+dUYhmEzTfxKmZmZSkhIsBbuBXF2dpaHh4fNAgBAWcSINwAAFci4ceMUFRWlkJAQdezYUYsWLVJiYqJ16vjEiRN14sQJLV++XJIUERGhRx99VAsWLFB4eLiSk5M1duxYtW/fXr6+vpJyR8VDQkLUoEEDZWVlae3atVq+fLnNndKffvppRUREKCAgQKmpqZo1a5YyMjI0ePDgm/8hAABwk1F4AwBQgURGRiotLU0zZ85UcnKyWrRoobVr1yowMFCSlJycbPNM7yFDhujs2bOaP3++xo8fr2rVqql79+56+eWXrX3OnTun0aNHKykpSVWqVFGTJk30zjvvKDIy0tonKSlJAwYM0OnTp1W7dm3ddttt2rZtm3W/AACUZxbjWvPEypCMjAx5enoqPT2dqWgAALsjL5U8PlMAQGlT2NzENd4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATFSswjs2NlZBQUFycXFRcHCwNm3adNW+Q4YMkcViybc0b97cpt+HH36oZs2aydnZWc2aNdNHH31UnNAAAAAAAChVilx4r1y5UmPHjtWkSZO0e/dudenSRT179lRiYmKB/efNm6fk5GTrcvz4cdWoUUMPPfSQtc/WrVsVGRmpqKgo/fjjj4qKilK/fv30/fffF//IAAAAAAAoBSyGYRhFWaFDhw5q166dFixYYG1r2rSp+vbtq5iYmOuuv2bNGt1///06cuSIAgMDJUmRkZHKyMjQ559/bu139913q3r16nrvvfcKFVdGRoY8PT2Vnp4uDw+PohwSAAAljrxU8vhMAQClTWFzU5FGvLOysrRr1y6FhYXZtIeFhWnLli2F2kZcXJx69OhhLbql3BHvK7cZHh5e6G0CAAAAAFBaVSpK59OnTys7O1teXl427V5eXkpJSbnu+snJyfr888/17rvv2rSnpKQUeZuZmZnKzMy0vs7IyCjMIQAAAAAAcFMV6+ZqFovF5rVhGPnaCrJs2TJVq1ZNffv2veFtxsTEyNPT07r4+/sXLngAAAAAAG6iIhXetWrVkqOjY76R6NTU1Hwj1lcyDENLlixRVFSUnJycbN7z9vYu8jYnTpyo9PR063L8+PGiHAoAAAAAADdFkQpvJycnBQcHKz4+3qY9Pj5eoaGh11z3m2++0aFDhxQdHZ3vvY4dO+bb5vr166+5TWdnZ3l4eNgsAAAAAACUNkW6xluSxo0bp6ioKIWEhKhjx45atGiREhMTNWrUKEm5I9EnTpzQ8uXLbdaLi4tThw4d1KJFi3zbfPLJJ3X77bfr5ZdfVp8+ffTxxx/ryy+/1ObNm4t5WAAAAAAAlA5FLrwjIyOVlpammTNnKjk5WS1atNDatWutdylPTk7O90zv9PR0ffjhh5o3b16B2wwNDdX777+vyZMna8qUKWrQoIFWrlypDh06FOOQAAAAAAAoPYr8HO/Simd7AgBKE/JSyeMzBQCUNqY8xxsAAAAAABQNhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAABVMbGysgoKC5OLiouDgYG3atOma/VesWKHWrVvL1dVVPj4+Gjp0qNLS0qzvr169WiEhIapWrZrc3NzUpk0bvf322ze8XwAAygsKbwAAKpCVK1dq7NixmjRpknbv3q0uXbqoZ8+eSkxMLLD/5s2bNWjQIEVHR2vfvn1atWqVduzYoeHDh1v71KhRQ5MmTdLWrVv1008/aejQoRo6dKi++OKLYu8XAIDyxGIYhmHvIEpCRkaGPD09lZ6eLg8PD3uHAwCo4EprXurQoYPatWunBQsWWNuaNm2qvn37KiYmJl//V199VQsWLNCvv/5qbXv99dc1e/ZsHT9+/Kr7adeunXr37q3nn3++WPstSGn9TAEAFVdhcxMj3gAAVBBZWVnatWuXwsLCbNrDwsK0ZcuWAtcJDQ1VUlKS1q5dK8MwdOrUKX3wwQfq3bt3gf0Nw9BXX32lAwcO6Pbbby/2fgEAKE8q2TsAAABwc5w+fVrZ2dny8vKyaffy8lJKSkqB64SGhmrFihWKjIzUhQsXdOnSJd177716/fXXbfqlp6erbt26yszMlKOjo2JjY3XXXXcVe7+SlJmZqczMTOvrjIyMIh0vAAClBSPe5VFSkrRhQ+5PAACuYLFYbF4bhpGvLc/+/fs1ZswYTZ06Vbt27dK6det05MgRjRo1yqZf1apVtWfPHu3YsUMvvPCCxo0bp40bNxZ7v5IUExMjT09P6+Lv71+EowQAoPRgxLu8iYuTRoyQcnIkBwdp0SIpOtreUQEASoFatWrJ0dEx3yhzampqvtHoPDExMerUqZOeeeYZSVKrVq3k5uamLl26aNasWfLx8ZEkOTg4qGHDhpKkNm3aKCEhQTExMeratWux9itJEydO1Lhx46yvMzIyKL4BAGUSI97lSVLS30W3lPtz5EhGvgEAkiQnJycFBwcrPj7epj0+Pl6hoaEFrnP+/Hk5ONh+XXB0dJSUO2J9NYZhWKeJF2e/kuTs7CwPDw+bBQCAsogR7/Lk4MG/i+482dnSoUOSn599YgIAlCrjxo1TVFSUQkJC1LFjRy1atEiJiYnWqeMTJ07UiRMntHz5cklSRESEHn30US1YsEDh4eFKTk7W2LFj1b59e/n6+krKHRUPCQlRgwYNlJWVpbVr12r58uU2dzC/3n4BACjPKLzLk0aNcqeXX158OzpK/5v6BwBAZGSk0tLSNHPmTCUnJ6tFixZau3atAgMDJUnJyck2z9YeMmSIzp49q/nz52v8+PGqVq2aunfvrpdfftna59y5cxo9erSSkpJUpUoVNWnSRO+8844iIyMLvV8UTdKOZB3clKJGXbzld6uPvcMBAFwHz/Eub+LicqeXZ2fnFt0LF3KNNwDYAXmp5PGZ5oobskkj3gpVjhzloGwtGrxF0cu62DssAKiQeI53RRUdLR09mntX86NHKboBAChHknYkW4tuScqRo0a+1VFJO5LtHBkA4FoovMsjPz+pa1eu6wYAoJw5uCnFWnTnyVYlHfrulJ0iAgAUBoV3OcRjvAEAKJ8adfGWg7Jt2hx1SQ07Xf2xbAAA+6PwLmfi4qTAQKl799yfcXH2jggAAJQUv1t9tGjwFjnqkqTconvh4K3cYA0ASjlurlaOJCXlFttX3tT86FFmnQPAzUZeKnl8pn9L2pGsQ9+dUsNOXhTdAGBHhc1NPE6sHOEx3gAAVAx+t/pQcANAGcJU83Ik7zHel+Mx3gAAAABgXxTe5Yifn7RoUW6xLf39GG9GuwEAAADAfphqXs5ER0vh4bnTyxs2pOgGAAAAAHuj8C6H/PwouAEAAACgtGCqOQAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgImKVXjHxsYqKChILi4uCg4O1qZNm67ZPzMzU5MmTVJgYKCcnZ3VoEEDLVmyxPr+xYsXNXPmTDVo0EAuLi5q3bq11q1bV5zQAAAAAAAoVSoVdYWVK1dq7Nixio2NVadOnbRw4UL17NlT+/fvV0BAQIHr9OvXT6dOnVJcXJwaNmyo1NRUXbp0yfr+5MmT9c4772jx4sVq0qSJvvjiC913333asmWL2rZtW/yjAwAAAADAziyGYRhFWaFDhw5q166dFixYYG1r2rSp+vbtq5iYmHz9161bp/79++vw4cOqUaNGgdv09fXVpEmT9Nhjj1nb+vbtK3d3d73zzjuFiisjI0Oenp5KT0+Xh4dHUQ4JAIASR14qeXymAIDSprC5qUhTzbOysrRr1y6FhYXZtIeFhWnLli0FrvPJJ58oJCREs2fPVt26ddW4cWM9/fTT+uuvv6x9MjMz5eLiYrNelSpVtHnz5qvGkpmZqYyMDJsFAAAAAIDSpkhTzU+fPq3s7Gx5eXnZtHt5eSklJaXAdQ4fPqzNmzfLxcVFH330kU6fPq3Ro0fr999/t17nHR4erjlz5uj2229XgwYN9NVXX+njjz9Wdnb2VWOJiYnRjBkzihI+AAAAAAA3XbFurmaxWGxeG4aRry1PTk6OLBaLVqxYofbt26tXr16aM2eOli1bZh31njdvnho1aqQmTZrIyclJjz/+uIYOHSpHR8erxjBx4kSlp6dbl+PHjxfnUAAAAAAAMFWRCu9atWrJ0dEx3+h2ampqvlHwPD4+Pqpbt648PT2tbU2bNpVhGEpKSpIk1a5dW2vWrNG5c+d07Ngx/fe//5W7u7uCgoKuGouzs7M8PDxsFgAAAAAASpsiFd5OTk4KDg5WfHy8TXt8fLxCQ0MLXKdTp046efKk/vzzT2vbL7/8IgcHB/n5+dn0dXFxUd26dXXp0iV9+OGH6tOnT1HCAwAAAACg1CnyVPNx48bpzTff1JIlS5SQkKCnnnpKiYmJGjVqlKTcKeCDBg2y9n/44YdVs2ZNDR06VPv379e3336rZ555RsOGDVOVKlUkSd9//71Wr16tw4cPa9OmTbr77ruVk5OjZ599toQOEwAAAAAA+yjyc7wjIyOVlpammTNnKjk5WS1atNDatWsVGBgoSUpOTlZiYqK1v7u7u+Lj4/XEE08oJCRENWvWVL9+/TRr1ixrnwsXLmjy5Mk6fPiw3N3d1atXL7399tuqVq3ajR8hAAAAAAB2VOTneJdWPNsTAFCakJdKHp8pAKC0MeU53gAAAAAAoGgovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAAAAAACYiMIbAAAAAAATUXgDAAAAAGAiCm8AAAAAAExE4Q0AAAAAgIkovAEAAAAAMBGFNwAAAAAAJqLwBgAAAADARBTeAABUMLGxsQoKCpKLi4uCg4O1adOma/ZfsWKFWrduLVdXV/n4+Gjo0KFKS0uzvr948WJ16dJF1atXV/Xq1dWjRw9t377dZhvTp0+XxWKxWby9vU05PgAAShsKbwAAKpCVK1dq7NixmjRpknbv3q0uXbqoZ8+eSkxMLLD/5s2bNWjQIEVHR2vfvn1atWqVduzYoeHDh1v7bNy4UQMGDNCGDRu0detWBQQEKCwsTCdOnLDZVvPmzZWcnGxd9u7da+qxAgBQWlB4AwBQgcyZM0fR0dEaPny4mjZtqrlz58rf318LFiwosP+2bdtUr149jRkzRkFBQercubNGjhypnTt3WvusWLFCo0ePVps2bdSkSRMtXrxYOTk5+uqrr2y2ValSJXl7e1uX2rVrm3qsAACUFhTeAABUEFlZWdq1a5fCwsJs2sPCwrRly5YC1wkNDVVSUpLWrl0rwzB06tQpffDBB+rdu/dV93P+/HldvHhRNWrUsGk/ePCgfH19FRQUpP79++vw4cPXjDczM1MZGRk2CwAAZRGFNwAAFcTp06eVnZ0tLy8vm3YvLy+lpKQUuE5oaKhWrFihyMhIOTk5ydvbW9WqVdPrr79+1f1MmDBBdevWVY8ePaxtHTp00PLly/XFF19o8eLFSklJUWhoqM214leKiYmRp6endfH39y/iEQMAUDpQeAMAUMFYLBab14Zh5GvLs3//fo0ZM0ZTp07Vrl27tG7dOh05ckSjRo0qsP/s2bP13nvvafXq1XJxcbG29+zZUw888IBatmypHj166LPPPpMkvfXWW1eNc+LEiUpPT7cux48fL+qhAgBQKlSydwAAAODmqFWrlhwdHfONbqempuYbBc8TExOjTp066ZlnnpEktWrVSm5uburSpYtmzZolHx8fa99XX31VL774or788ku1atXqmrG4ubmpZcuWOnjw4FX7ODs7y9nZubCHBwBAqcWINwAAFYSTk5OCg4MVHx9v0x4fH6/Q0NAC1zl//rwcHGy/Ljg6OkrKHSnP88orr+j555/XunXrFBISct1YMjMzlZCQYFO4AwBQXlF4AwBQgYwbN05vvvmmlixZooSEBD311FNKTEy0Th2fOHGiBg0aZO0fERGh1atXa8GCBTp8+LC+++47jRkzRu3bt5evr6+k3OnlkydP1pIlS1SvXj2lpKQoJSVFf/75p3U7Tz/9tL755hsdOXJE33//vR588EFlZGRo8ODBN/cDAADADphqDgBABRIZGam0tDTNnDlTycnJatGihdauXavAwEBJUnJyss0zvYcMGaKzZ89q/vz5Gj9+vKpVq6bu3bvr5ZdftvaJjY1VVlaWHnzwQZt9TZs2TdOnT5ckJSUlacCAATp9+rRq166t2267Tdu2bbPuFwCA8sxiXD5PrAzLyMiQp6en0tPT5eHhYe9wAAAVHHmp5PGZAgBKm8LmJqaaAwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvlD5JSdKGDbk/AQBAuUOqB1DRUHijdImLkwIDpe7dc3/Gxdk7IgAAUIJyU73xv1RvkOoBVAgU3ig9kpKkESOUlOOjDeqqpBwfaeRITocDAFBOJCVJIx7NUU6ORZKUk2PRyBE5pHoA5R6FN0qPgwcVlzNEgTqm7tqgQB1TXPZg6dAhe0cGAABKwMEtvynHsP36mZ3joENbf7NTRABwc1B4o9RIcm+iEVqkHDlKknLkqJFaqCS3W+wcGQAAKAmNdFAOyrZpc9QlNRQn2QGUbxTeKDUO/uljLbrzZKuSDp3zsVNEAACgJPmFBmiRZZQcdUlSbtG90PIP+XX0t3NkAGAuCm+UGo0aSQ5X/EY6OkoNG9onHgAAUML8/BS9+DYddWigDeqqow4NFL34NsnPz96RAYCpKtk7ACCPn5+0aFHu/dSys3OL7oULycUAAJQr0dHyCw+X36FDuWfXSfQAKgAKb5Qq0dFSeHju/dTIxQAAlFN+fiR5ABUKhTdKHXIxAAAAgPKEa7wBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAoAiSkqQNG3J/AkBhUHgDJYxkDABA+RUXJwUGSt275/6Mi7N3RADKAgpvoASRjAEAKL+SkqQRI6ScnNzXOTnSyJGcbAdwfRTeQAkhGQMAUL4dPPh3ns+TnS0dOmSfeACUHcUqvGNjYxUUFCQXFxcFBwdr06ZN1+yfmZmpSZMmKTAwUM7OzmrQoIGWLFli02fu3Lm65ZZbVKVKFfn7++upp57ShQsXihMeYBckYwAAyrdGjSSHK749OzpKDRvaJx4AZUeloq6wcuVKjR07VrGxserUqZMWLlyonj17av/+/QoICChwnX79+unUqVOKi4tTw4YNlZqaqkuXLlnfX7FihSZMmKAlS5YoNDRUv/zyi4YMGSJJeu2114p3ZMBNlpeMLy++ScYAAJQffn7SokW5M9qys3Pz/MKFue0AcC0WwzCMoqzQoUMHtWvXTgsWLLC2NW3aVH379lVMTEy+/uvWrVP//v11+PBh1ahRo8BtPv7440pISNBXX31lbRs/fry2b99+3dH0PBkZGfL09FR6ero8PDyKckhAiYmLy5+Mo6PtHRUAeyAvlTw+U5QWSUm5M9oaNqToBiq6wuamIk01z8rK0q5duxQWFmbTHhYWpi1bthS4zieffKKQkBDNnj1bdevWVePGjfX000/rr7/+svbp3Lmzdu3ape3bt0uSDh8+rLVr16p3795XjSUzM1MZGRk2C2Bv0dHS0aO5dzU/epSiGwCA8sjPT+ralaIbQOEVaar56dOnlZ2dLS8vL5t2Ly8vpaSkFLjO4cOHtXnzZrm4uOijjz7S6dOnNXr0aP3+++/W67z79++v3377TZ07d5ZhGLp06ZL+8Y9/aMKECVeNJSYmRjNmzChK+MBN4edHIgYAAADwt2LdXM1isdi8NgwjX1uenJwcWSwWrVixQu3bt1evXr00Z84cLVu2zDrqvXHjRr3wwguKjY3VDz/8oNWrV+vTTz/V888/f9UYJk6cqPT0dOty/Pjx4hwKUPJ4kDcAAOUbuR5AERWp8K5Vq5YcHR3zjW6npqbmGwXP4+Pjo7p168rT09Pa1rRpUxmGoaT//bGaMmWKoqKiNHz4cLVs2VL33XefXnzxRcXExCjnyttE/4+zs7M8PDxsFsDueJA3AADlWznI9Zw3AG6+IhXeTk5OCg4OVnx8vE17fHy8QkNDC1ynU6dOOnnypP78809r2y+//CIHBwf5/W8+7vnz5+VwxbMZHB0dZRiGinjvN8B+ysmDvEnGAABcRTnI9eXgvAFQJhV5qvm4ceP05ptvasmSJUpISNBTTz2lxMREjRo1SlLuFPBBgwZZ+z/88MOqWbOmhg4dqv379+vbb7/VM888o2HDhqlKlSqSpIiICC1YsEDvv/++jhw5ovj4eE2ZMkX33nuvHB0dS+hQAZOVgwd5k4wBALiGMp7ry8F5A6DMKvJzvCMjI5WWlqaZM2cqOTlZLVq00Nq1axUYGChJSk5OVmJiorW/u7u74uPj9cQTTygkJEQ1a9ZUv379NGvWLGufyZMny2KxaPLkyTpx4oRq166tiIgIvfDCCyVwiMBNUsYf5H21ZBwezs3iAACQVOZz/bXOG5DrAXMV+TnepRXP9kSpUIYf5L1hQ+5Id0HtXbve9HCAMo+8VPL4TFEqlOFcn5SUO6PtyvMGR49SeAPFVdjcVOQRbwDXEB2dO0R86FDu2e8ylMXK+El8AABujjKc6/38pEWL8p83KEOHAJRZFN5ASSujD/ImGQMAUEhlNNdLZfq8AVCmUXgDsCIZAwBQ/pXh8wZAmUXhDcAGyRgAAAAoWUV+nBgAAAAAACg8Cm8AAACgIklKyn1sSVl9gHdZjx8VEoU3AFskMwAAyq+4uNxninXvnvszLs7eERVNWY8fFRaFN4C/lYdkxokDAAAKlpQkjRjx97NDc3JyH2dSVnJmWY8fFRqFN4Bc5SGZlYcTBwAAmOXgwb/zfJ7s7NzHmZQFZT1+VGgU3gBylfVkVh5OHAAAYKZGjSSHK77+OzrmPkO0LCjr8edhdl6FROENIFdZT2b/O3GQpLraoK5KUt2ydeIgD8kYAGAWPz9p0aLc/C7l/ly4sOw8R7Ssxy8xO68Co/AGkKusJ7NGjRRnGa5AHVN3bVCgjinOMrzsnDiQSMYAAPNFR0tHj+ae5D16NPd1WRIdraStx7Vhzm4lbT1etuJndl6FZjEMw7B3ECUhIyNDnp6eSk9Pl4eHh73DAcqupKTcUeKGDctO0a3csAMDcpRj/H0+0dEhR0ePOZSNw0hKkgIDlZTjo4NqpEY6KD/HlNwvRWXiAHAl8lLJ4zMFEBf3d+3q4JA7ZlBmau8NG6Tu3ZWkun/nep3Ibe/a1d7RFV5SUu5Mw0aNyu53lBI8hsLmJka8Adjy88v941/G/pAePCiboluSsnMcys5M84MHFZczxHbEPntw2ZsqDwCAScr8gDGz80oHOx0DhTeAcqGsX6Ke5N5EI7RIOcqd6p8jR43UQiW53WLnyIqorF+jXtbjB4ByrMzfB1Z+GqGFtrneslBJKiODHWX+zIfsegwU3gDKhbJ+ifrBP32siThPtirp0DkfO0VUDHFxSgoI1YbuM5UUEFr2zoKXh7P4AFCOlfWT7OVhdl6ZPvMh2fUYKLwBlBtl+X4xZf3LhJKSFPfoNgUaR3KnzxlHFPfotrJzFvx/Z8CTcnxy74qf41P2zuIXQWxsrIKCguTi4qLg4GBt2rTpmv1XrFih1q1by9XVVT4+Pho6dKjS0tKs7y9evFhdunRR9erVVb16dfXo0UPbt2+/4f0CwOXK+kn2Mp/r/3cANk+QKVMHILseA4U3gHKljF6iXua/TCRtSdQI4w3b6XPGgtw7zpYFFega+5UrV2rs2LGaNGmSdu/erS5duqhnz55KTEwssP/mzZs1aNAgRUdHa9++fVq1apV27Nih4cOHW/ts3LhRAwYM0IYNG7R161YFBAQoLCxMJ06cKPZ+AaAgZfkke1nP9fLzU1zURttc+ciGMnQAsusxcFdzAChFyuhN5bXh37+pe2TtAtu7PpS/vbRJ2pGswPZ1bKb7O+qSjm7/TX63Fm+6f2nNSx06dFC7du20YMECa1vTpk3Vt29fxcTE5Ov/6quvasGCBfr111+tba+//rpmz56t48cLPrGSnZ2t6tWra/78+Ro0aFCx9luQ0vqZAkBRlNVc/78HsNjM1HZ0LFsPYDHjGLirOQCUQWV1xL5RaG05WGyvmXJ0yFHDjqW/6JbKyTX2hZCVlaVdu3YpLCzMpj0sLExbtmwpcJ3Q0FAlJSVp7dq1MgxDp06d0gcffKDevXtfdT/nz5/XxYsXVaNGjWLvV5IyMzOVkZFhswBAWVdWcz2XeN8YCm8AwA3z85MWLXaQo2PuJCpHR0MLF5WRZ6irHFx3V0inT59Wdna2vLy8bNq9vLyUkpJS4DqhoaFasWKFIiMj5eTkJG9vb1WrVk2vv/76VfczYcIE1a1bVz169Cj2fiUpJiZGnp6e1sXf37+whwoAKGHlIVfa8xgovAEAJSL3ujvL/667s3DdXSlmsVhsXhuGka8tz/79+zVmzBhNnTpVu3bt0rp163TkyBGNGjWqwP6zZ8/We++9p9WrV8vFxaXY+5WkiRMnKj093bpcbWo7AMB85SFX2vMYKpm/CwBAReHnV7YS8OWio6Xw8LJ53V1h1apVS46OjvlGmVNTU/ONRueJiYlRp06d9Mwzz0iSWrVqJTc3N3Xp0kWzZs2Sj8/f0/FfffVVvfjii/ryyy/VqlWrG9qvJDk7O8vZ2bnIxwkAMEd5yJX2OgZGvAEA+J+yet1dYTk5OSk4OFjx8fE27fHx8QoNDS1wnfPnz8vhinl5jv8bKrj8/qyvvPKKnn/+ea1bt04hISE3vF8AQOlUHnKlPY6BEW8AACqQcePGKSoqSiEhIerYsaMWLVqkxMRE69TxiRMn6sSJE1q+fLkkKSIiQo8++qgWLFig8PBwJScna+zYsWrfvr18fX0l5U4vnzJlit59913Vq1fPOrLt7u4ud3f3Qu0XAIDyjMIbAIAKJDIyUmlpaZo5c6aSk5PVokULrV27VoGBgZKk5ORkm2drDxkyRGfPntX8+fM1fvx4VatWTd27d9fLL79s7RMbG6usrCw9+OCDNvuaNm2apk+fXqj9AgBQnvEcbwAATEBeKnl8pgCA0obneAMAAAAAUApQeAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSi8AQAAAAAwEYU3AAAAAAAmovAGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIKbwAAAAAATEThDQAAAACAiSrZO4CSYhiGJCkjI8POkQAA8Hc+ystPuHHkegBAaVPYfF9uCu+zZ89Kkvz9/e0cCQAAfzt79qw8PT3tHUa5QK4HAJRW18v3FqOcnIrPycnRyZMnVbVqVVkslhvaVkZGhvz9/XX8+HF5eHiUUIQ3D/HbF/HbF/HbF/H/zTAMnT17Vr6+vnJw4MqukkCu/xvx2xfx2xfx21dZj1+yT74vNyPeDg4O8vPzK9Ftenh4lNlfJon47Y347Yv47Yv4czHSXbLI9fkRv30Rv30Rv32V9film5vvOQUPAAAAAICJKLwBAAAAADARhXcBnJ2dNW3aNDk7O9s7lGIhfvsifvsifvsifpQVZf3/mvjti/jti/jtq6zHL9nnGMrNzdUAAAAAACiNGPEGAAAAAMBEFN4AAAAAAJiIwhsAAAAAABNReAMAAAAAYCIK7yvExsYqKChILi4uCg4O1qZNm+wdUqF9++23ioiIkK+vrywWi9asWWPvkIokJiZGt956q6pWrao6deqob9++OnDggL3DKrQFCxaoVatW8vDwkIeHhzp27KjPP//c3mEVS0xMjCwWi8aOHWvvUApt+vTpslgsNou3t7e9wyqSEydO6JFHHlHNmjXl6uqqNm3aaNeuXfYOq1Dq1auX7/O3WCx67LHH7B1aoVy6dEmTJ09WUFCQqlSpovr162vmzJnKycmxd2gwSVnN9+R6+ypPuV4qe/meXG9f5PobQ+F9mZUrV2rs2LGaNGmSdu/erS5duqhnz55KTEy0d2iFcu7cObVu3Vrz58+3dyjF8s033+ixxx7Ttm3bFB8fr0uXLiksLEznzp2zd2iF4ufnp5deekk7d+7Uzp071b17d/Xp00f79u2zd2hFsmPHDi1atEitWrWydyhF1rx5cyUnJ1uXvXv32jukQvvjjz/UqVMnVa5cWZ9//rn279+vf/3rX6pWrZq9QyuUHTt22Hz28fHxkqSHHnrIzpEVzssvv6w33nhD8+fPV0JCgmbPnq1XXnlFr7/+ur1DgwnKcr4n19tXecn1UtnN9+R6+yHX3yADVu3btzdGjRpl09akSRNjwoQJdoqo+CQZH330kb3DuCGpqamGJOObb76xdyjFVr16dePNN9+0dxiFdvbsWaNRo0ZGfHy8cccddxhPPvmkvUMqtGnTphmtW7e2dxjF9txzzxmdO3e2dxgl5sknnzQaNGhg5OTk2DuUQundu7cxbNgwm7b777/feOSRR+wUEcxUXvI9ub50KGu53jDKbr4n15cu5PqiYcT7f7KysrRr1y6FhYXZtIeFhWnLli12iqpiS09PlyTVqFHDzpEUXXZ2tt5//32dO3dOHTt2tHc4hfbYY4+pd+/e6tGjh71DKZaDBw/K19dXQUFB6t+/vw4fPmzvkArtk08+UUhIiB566CHVqVNHbdu21eLFi+0dVrFkZWXpnXfe0bBhw2SxWOwdTqF07txZX331lX755RdJ0o8//qjNmzerV69edo4MJY18X7qQ6+2jLOd7cn3pQK4vuko3ZS9lwOnTp5WdnS0vLy+bdi8vL6WkpNgpqorLMAyNGzdOnTt3VosWLewdTqHt3btXHTt21IULF+Tu7q6PPvpIzZo1s3dYhfL+++/rhx9+0I4dO+wdSrF06NBBy5cvV+PGjXXq1CnNmjVLoaGh2rdvn2rWrGnv8K7r8OHDWrBggcaNG6d//vOf2r59u8aMGSNnZ2cNGjTI3uEVyZo1a3TmzBkNGTLE3qEU2nPPPaf09HQ1adJEjo6Oys7O1gsvvKABAwbYOzSUMPJ96UGut4+ynO/J9aUHub7oKLyvcOUZG8MwysxZnPLk8ccf108//aTNmzfbO5QiueWWW7Rnzx6dOXNGH374oQYPHqxvvvmm1Cfk48eP68knn9T69evl4uJi73CKpWfPntZ/t2zZUh07dlSDBg301ltvady4cXaMrHBycnIUEhKiF198UZLUtm1b7du3TwsWLChzyTguLk49e/aUr6+vvUMptJUrV+qdd97Ru+++q+bNm2vPnj0aO3asfH19NXjwYHuHBxOQ7+2PXH/zlfV8T64vPcj1RUfh/T+1atWSo6NjvrPdqamp+c6Kw1xPPPGEPvnkE3377bfy8/OzdzhF4uTkpIYNG0qSQkJCtGPHDs2bN08LFy60c2TXtmvXLqWmpio4ONjalp2drW+//Vbz589XZmamHB0d7Rhh0bm5ually5Y6ePCgvUMpFB8fn3xf2po2baoPP/zQThEVz7Fjx/Tll19q9erV9g6lSJ555hlNmDBB/fv3l5T7he7YsWOKiYmh8C5nyPelA7nePspbvifX2we5vni4xvt/nJycFBwcbL07X574+HiFhobaKaqKxTAMPf7441q9erW+/vprBQUF2TukG2YYhjIzM+0dxnXdeeed2rt3r/bs2WNdQkJCNHDgQO3Zs6dMJeE8mZmZSkhIkI+Pj71DKZROnTrle6TOL7/8osDAQDtFVDxLly5VnTp11Lt3b3uHUiTnz5+Xg4NtSnR0dORxYuUQ+d6+yPX2Vd7yPbnePsj1xcOI92XGjRunqKgohYSEqGPHjlq0aJESExM1atQoe4dWKH/++acOHTpkfX3kyBHt2bNHNWrUUEBAgB0jK5zHHntM7777rj7++GNVrVrVOhrh6empKlWq2Dm66/vnP/+pnj17yt/fX2fPntX777+vjRs3at26dfYO7bqqVq2a7/o6Nzc31axZs8xcd/f0008rIiJCAQEBSk1N1axZs5SRkVFmRiufeuophYaG6sUXX1S/fv20fft2LVq0SIsWLbJ3aIWWk5OjpUuXavDgwapUqWyll4iICL3wwgsKCAhQ8+bNtXv3bs2ZM0fDhg2zd2gwQVnO9+R6+yrLuV4q+/meXG9/5PobcFPunV6G/L//9/+MwMBAw8nJyWjXrl2ZerzFhg0bDEn5lsGDB9s7tEIpKHZJxtKlS+0dWqEMGzbM+rtTu3Zt48477zTWr19v77CKrSw9XsQwDCMyMtLw8fExKleubPj6+hr333+/sW/fPnuHVST/+c9/jBYtWhjOzs5GkyZNjEWLFtk7pCL54osvDEnGgQMH7B1KkWVkZBhPPvmkERAQYLi4uBj169c3Jk2aZGRmZto7NJikrOZ7cr19lbdcbxhlK9+T6+2PXF98FsMwjJtT4gMAAAAAUPFwjTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE1F4AwAAAABgIgpvAAAAAABMROENAAAAAICJKLwBAAAAADARhTcAAAAAACai8AYAAAAAwEQU3gAAAAAAmIjCGwAAAAAAE/1/E59oRt4JlzUAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n = len(run_hist.history[\"loss\"])-1\n",
        "\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(range(n), (run_hist.history[\"loss\"][1:]),'r.', label=\"Train Loss\")\n",
        "ax.plot(range(n), (run_hist.history[\"val_loss\"][1:]),'b.', label=\"Validation Loss\")\n",
        "ax.legend()\n",
        "ax.set_title('Loss over iterations')\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(range(n), (run_hist.history[\"root_mean_squared_error\"][1:]),'r.', label=\"Train RMSE\")\n",
        "ax.plot(range(n), (run_hist.history[\"val_root_mean_squared_error\"][1:]),'b.', label=\"Validation RMSE\")\n",
        "ax.legend()\n",
        "ax.set_title('RMSE over iterations')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# one can save the weights to a file\n",
        "model.save_weights(\"recommender_net_weights.weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d48c27e-8e74-4482-9954-ec1381d9facf"
      },
      "source": [
        "#### Evaluate the trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3e0ced73-14d3-4678-8be2-c63049c3abab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - loss: 0.6847 - root_mean_squared_error: 0.8247\n",
            "Test loss:  0.6824983358383179\n",
            "Test root_mean_squared_error:  0.823388934135437\n"
          ]
        }
      ],
      "source": [
        "evaluate = model.evaluate(x=[x_test[:,0], x_test[:,1]], y=y_test, batch_size=16)\n",
        "\n",
        "print('Test loss: ', evaluate[0])\n",
        "print('Test root_mean_squared_error: ', evaluate[1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step\n",
            "(23331, 1, 1)\n"
          ]
        }
      ],
      "source": [
        "testPredict = model.predict(x=[x_test[:,0], x_test[:,1]])\n",
        "print(testPredict.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c94ff96c-0090-420a-94c2-10cc606ccde0"
      },
      "source": [
        "### Extract the user and item embedding vectors as latent feature vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1f45d6a-b74d-496e-80e9-1775b1820302"
      },
      "source": [
        "Now, we have trained our model and it can predict the ratings with relatively small RMSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54a2d550-80f2-405a-9dcb-9cbbeea21f61"
      },
      "source": [
        "In the model, the `user_embedding_layer` and `item_embedding_layer` layers contain the trained weights. Essentially, they are the latent user and item features learned by the neural network and will be used to predict the interaction. As such, while training the neural network to predict rating, the embedding layers are simultaneously trained to extract the embedding user and item features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "279bf727-4927-405d-9844-bae39a0cea1e"
      },
      "source": [
        "We can easily get the actual weights using `model.get_layer().get_weights()` methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "d75b07bd-ec90-4ee4-b302-1b2a29c0ce57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User features shape: (33901, 30)\n"
          ]
        }
      ],
      "source": [
        "# User features\n",
        "user_latent_features = model.get_layer('embedding_layer_user').get_weights()[0]\n",
        "print(f\"User features shape: {user_latent_features.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "31ed97d4-2725-4540-85fc-8f9e63b3a118"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Item features shape: (126, 30)\n"
          ]
        }
      ],
      "source": [
        "item_latent_features = model.get_layer('embedding_layer_item').get_weights()[0]\n",
        "print(f\"Item features shape: {item_latent_features.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a42737e4-f49f-43a9-9154-c2777a1d99b2"
      },
      "source": [
        "Now, each user of the total 33901 users has been transformed into a 50 x 1 latent feature vector and each item of the total 126 has been transformed into a 50 x 1 latent feature vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>user</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.106539</td>\n",
              "      <td>0.169725</td>\n",
              "      <td>0.037759</td>\n",
              "      <td>-0.179715</td>\n",
              "      <td>0.004930</td>\n",
              "      <td>-0.025669</td>\n",
              "      <td>-0.081321</td>\n",
              "      <td>-0.060345</td>\n",
              "      <td>-0.005838</td>\n",
              "      <td>-0.079697</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047092</td>\n",
              "      <td>-0.258899</td>\n",
              "      <td>-0.043900</td>\n",
              "      <td>0.003739</td>\n",
              "      <td>0.197900</td>\n",
              "      <td>0.152393</td>\n",
              "      <td>0.024159</td>\n",
              "      <td>0.186125</td>\n",
              "      <td>-0.017375</td>\n",
              "      <td>1889878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.043064</td>\n",
              "      <td>0.014002</td>\n",
              "      <td>0.107306</td>\n",
              "      <td>0.064301</td>\n",
              "      <td>0.106295</td>\n",
              "      <td>-0.053030</td>\n",
              "      <td>0.159673</td>\n",
              "      <td>0.099222</td>\n",
              "      <td>0.039183</td>\n",
              "      <td>-0.015562</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002050</td>\n",
              "      <td>-0.059056</td>\n",
              "      <td>0.067193</td>\n",
              "      <td>0.075977</td>\n",
              "      <td>-0.055027</td>\n",
              "      <td>0.058501</td>\n",
              "      <td>-0.007581</td>\n",
              "      <td>-0.167742</td>\n",
              "      <td>0.052345</td>\n",
              "      <td>1342067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.039600</td>\n",
              "      <td>0.171552</td>\n",
              "      <td>0.004101</td>\n",
              "      <td>0.035966</td>\n",
              "      <td>-0.149341</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>-0.165297</td>\n",
              "      <td>-0.110185</td>\n",
              "      <td>0.033201</td>\n",
              "      <td>0.105581</td>\n",
              "      <td>...</td>\n",
              "      <td>0.161102</td>\n",
              "      <td>0.024662</td>\n",
              "      <td>0.069054</td>\n",
              "      <td>-0.066513</td>\n",
              "      <td>0.029164</td>\n",
              "      <td>0.026886</td>\n",
              "      <td>0.148648</td>\n",
              "      <td>0.096873</td>\n",
              "      <td>0.044408</td>\n",
              "      <td>1990814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.120070</td>\n",
              "      <td>-0.198679</td>\n",
              "      <td>0.034901</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.020262</td>\n",
              "      <td>0.233966</td>\n",
              "      <td>-0.125914</td>\n",
              "      <td>0.086001</td>\n",
              "      <td>0.098813</td>\n",
              "      <td>0.026997</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.150161</td>\n",
              "      <td>0.077233</td>\n",
              "      <td>-0.055136</td>\n",
              "      <td>-0.007019</td>\n",
              "      <td>0.065199</td>\n",
              "      <td>0.159676</td>\n",
              "      <td>-0.101342</td>\n",
              "      <td>-0.154561</td>\n",
              "      <td>0.096996</td>\n",
              "      <td>380098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.030299</td>\n",
              "      <td>0.059425</td>\n",
              "      <td>-0.089233</td>\n",
              "      <td>-0.037715</td>\n",
              "      <td>0.066093</td>\n",
              "      <td>-0.045554</td>\n",
              "      <td>0.048373</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>0.032430</td>\n",
              "      <td>-0.015075</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013387</td>\n",
              "      <td>0.070763</td>\n",
              "      <td>0.048061</td>\n",
              "      <td>-0.017882</td>\n",
              "      <td>0.118738</td>\n",
              "      <td>-0.011427</td>\n",
              "      <td>-0.124837</td>\n",
              "      <td>-0.010020</td>\n",
              "      <td>0.081052</td>\n",
              "      <td>779563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.106539  0.169725  0.037759 -0.179715  0.004930 -0.025669 -0.081321   \n",
              "1  0.043064  0.014002  0.107306  0.064301  0.106295 -0.053030  0.159673   \n",
              "2  0.039600  0.171552  0.004101  0.035966 -0.149341 -0.000231 -0.165297   \n",
              "3  0.120070 -0.198679  0.034901 -0.085777 -0.020262  0.233966 -0.125914   \n",
              "4 -0.030299  0.059425 -0.089233 -0.037715  0.066093 -0.045554  0.048373   \n",
              "\n",
              "          7         8         9  ...        21        22        23        24  \\\n",
              "0 -0.060345 -0.005838 -0.079697  ...  0.047092 -0.258899 -0.043900  0.003739   \n",
              "1  0.099222  0.039183 -0.015562  ... -0.002050 -0.059056  0.067193  0.075977   \n",
              "2 -0.110185  0.033201  0.105581  ...  0.161102  0.024662  0.069054 -0.066513   \n",
              "3  0.086001  0.098813  0.026997  ... -0.150161  0.077233 -0.055136 -0.007019   \n",
              "4  0.000093  0.032430 -0.015075  ...  0.013387  0.070763  0.048061 -0.017882   \n",
              "\n",
              "         25        26        27        28        29     user  \n",
              "0  0.197900  0.152393  0.024159  0.186125 -0.017375  1889878  \n",
              "1 -0.055027  0.058501 -0.007581 -0.167742  0.052345  1342067  \n",
              "2  0.029164  0.026886  0.148648  0.096873  0.044408  1990814  \n",
              "3  0.065199  0.159676 -0.101342 -0.154561  0.096996   380098  \n",
              "4  0.118738 -0.011427 -0.124837 -0.010020  0.081052   779563  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_latent_df = pd.DataFrame(data=user_latent_features)#, \n",
        "                              #columns=['UFeature0','UFeature1','UFeature2','UFeature3','UFeature4','UFeature5','UFeature6','UFeature7','UFeature8','UFeature9','UFeature10','UFeature11','UFeature12','UFeature13','UFeature14','UFeature15'])\n",
        "user_latent_df['user'] = user_latent_df.index.map(user_idx2id_dict)\n",
        "user_latent_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>item</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.016241</td>\n",
              "      <td>-0.103051</td>\n",
              "      <td>0.007395</td>\n",
              "      <td>0.054987</td>\n",
              "      <td>0.055067</td>\n",
              "      <td>0.006007</td>\n",
              "      <td>-0.042313</td>\n",
              "      <td>0.001686</td>\n",
              "      <td>0.073498</td>\n",
              "      <td>-0.035578</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003626</td>\n",
              "      <td>0.015632</td>\n",
              "      <td>-0.010677</td>\n",
              "      <td>-0.073484</td>\n",
              "      <td>-0.097091</td>\n",
              "      <td>-0.072879</td>\n",
              "      <td>-0.110306</td>\n",
              "      <td>0.079633</td>\n",
              "      <td>-0.084364</td>\n",
              "      <td>CC0101EN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.027003</td>\n",
              "      <td>-0.086743</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>-0.007644</td>\n",
              "      <td>0.075378</td>\n",
              "      <td>0.189957</td>\n",
              "      <td>0.059592</td>\n",
              "      <td>0.017654</td>\n",
              "      <td>-0.032787</td>\n",
              "      <td>-0.120175</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.021713</td>\n",
              "      <td>-0.040749</td>\n",
              "      <td>0.232137</td>\n",
              "      <td>-0.021132</td>\n",
              "      <td>-0.026330</td>\n",
              "      <td>0.062515</td>\n",
              "      <td>0.072006</td>\n",
              "      <td>-0.022570</td>\n",
              "      <td>CL0101EN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.103843</td>\n",
              "      <td>0.217440</td>\n",
              "      <td>0.176883</td>\n",
              "      <td>0.058587</td>\n",
              "      <td>-0.037320</td>\n",
              "      <td>0.041901</td>\n",
              "      <td>0.109647</td>\n",
              "      <td>0.077550</td>\n",
              "      <td>-0.010427</td>\n",
              "      <td>-0.013611</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.057169</td>\n",
              "      <td>0.124602</td>\n",
              "      <td>-0.197989</td>\n",
              "      <td>-0.107890</td>\n",
              "      <td>-0.111450</td>\n",
              "      <td>-0.114045</td>\n",
              "      <td>0.058036</td>\n",
              "      <td>-0.199624</td>\n",
              "      <td>0.259155</td>\n",
              "      <td>ML0120ENv3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.047253</td>\n",
              "      <td>-0.035368</td>\n",
              "      <td>-0.078138</td>\n",
              "      <td>0.000162</td>\n",
              "      <td>0.033345</td>\n",
              "      <td>-0.037298</td>\n",
              "      <td>0.009164</td>\n",
              "      <td>-0.023665</td>\n",
              "      <td>-0.117988</td>\n",
              "      <td>0.034094</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116564</td>\n",
              "      <td>0.025722</td>\n",
              "      <td>0.001413</td>\n",
              "      <td>0.140056</td>\n",
              "      <td>-0.036409</td>\n",
              "      <td>-0.062878</td>\n",
              "      <td>0.033082</td>\n",
              "      <td>0.042508</td>\n",
              "      <td>-0.130935</td>\n",
              "      <td>BD0211EN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.050540</td>\n",
              "      <td>0.057302</td>\n",
              "      <td>-0.055438</td>\n",
              "      <td>-0.026285</td>\n",
              "      <td>-0.052446</td>\n",
              "      <td>-0.046933</td>\n",
              "      <td>0.034328</td>\n",
              "      <td>-0.009827</td>\n",
              "      <td>0.057384</td>\n",
              "      <td>-0.068493</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013957</td>\n",
              "      <td>-0.095489</td>\n",
              "      <td>0.006763</td>\n",
              "      <td>-0.055791</td>\n",
              "      <td>0.034223</td>\n",
              "      <td>-0.041170</td>\n",
              "      <td>0.082775</td>\n",
              "      <td>-0.108192</td>\n",
              "      <td>0.064673</td>\n",
              "      <td>DS0101EN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0 -0.016241 -0.103051  0.007395  0.054987  0.055067  0.006007 -0.042313   \n",
              "1 -0.027003 -0.086743  0.071170 -0.007644  0.075378  0.189957  0.059592   \n",
              "2 -0.103843  0.217440  0.176883  0.058587 -0.037320  0.041901  0.109647   \n",
              "3 -0.047253 -0.035368 -0.078138  0.000162  0.033345 -0.037298  0.009164   \n",
              "4 -0.050540  0.057302 -0.055438 -0.026285 -0.052446 -0.046933  0.034328   \n",
              "\n",
              "          7         8         9  ...        21        22        23        24  \\\n",
              "0  0.001686  0.073498 -0.035578  ... -0.003626  0.015632 -0.010677 -0.073484   \n",
              "1  0.017654 -0.032787 -0.120175  ...  0.000152  0.021713 -0.040749  0.232137   \n",
              "2  0.077550 -0.010427 -0.013611  ... -0.057169  0.124602 -0.197989 -0.107890   \n",
              "3 -0.023665 -0.117988  0.034094  ...  0.116564  0.025722  0.001413  0.140056   \n",
              "4 -0.009827  0.057384 -0.068493  ...  0.013957 -0.095489  0.006763 -0.055791   \n",
              "\n",
              "         25        26        27        28        29        item  \n",
              "0 -0.097091 -0.072879 -0.110306  0.079633 -0.084364    CC0101EN  \n",
              "1 -0.021132 -0.026330  0.062515  0.072006 -0.022570    CL0101EN  \n",
              "2 -0.111450 -0.114045  0.058036 -0.199624  0.259155  ML0120ENv3  \n",
              "3 -0.036409 -0.062878  0.033082  0.042508 -0.130935    BD0211EN  \n",
              "4  0.034223 -0.041170  0.082775 -0.108192  0.064673    DS0101EN  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "item_latent_df = pd.DataFrame(data=item_latent_features)#, \n",
        "                              #columns=['IFeature0','IFeature1','IFeature2','IFeature3','IFeature4','IFeature5','IFeature6','IFeature7','IFeature8','IFeature9','IFeature10','IFeature11','IFeature12','IFeature13','IFeature14','IFeature15'])\n",
        "item_latent_df['item'] = item_latent_df.index.map(course_idx2id_dict)\n",
        "item_latent_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "      <th>0_x</th>\n",
              "      <th>1_x</th>\n",
              "      <th>2_x</th>\n",
              "      <th>3_x</th>\n",
              "      <th>4_x</th>\n",
              "      <th>5_x</th>\n",
              "      <th>6_x</th>\n",
              "      <th>...</th>\n",
              "      <th>20_y</th>\n",
              "      <th>21_y</th>\n",
              "      <th>22_y</th>\n",
              "      <th>23_y</th>\n",
              "      <th>24_y</th>\n",
              "      <th>25_y</th>\n",
              "      <th>26_y</th>\n",
              "      <th>27_y</th>\n",
              "      <th>28_y</th>\n",
              "      <th>29_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1889878</td>\n",
              "      <td>CC0101EN</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.106539</td>\n",
              "      <td>0.169725</td>\n",
              "      <td>0.037759</td>\n",
              "      <td>-0.179715</td>\n",
              "      <td>0.004930</td>\n",
              "      <td>-0.025669</td>\n",
              "      <td>-0.081321</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.073589</td>\n",
              "      <td>-0.003626</td>\n",
              "      <td>0.015632</td>\n",
              "      <td>-0.010677</td>\n",
              "      <td>-0.073484</td>\n",
              "      <td>-0.097091</td>\n",
              "      <td>-0.072879</td>\n",
              "      <td>-0.110306</td>\n",
              "      <td>0.079633</td>\n",
              "      <td>-0.084364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1342067</td>\n",
              "      <td>CL0101EN</td>\n",
              "      <td>3</td>\n",
              "      <td>0.043064</td>\n",
              "      <td>0.014002</td>\n",
              "      <td>0.107306</td>\n",
              "      <td>0.064301</td>\n",
              "      <td>0.106295</td>\n",
              "      <td>-0.053030</td>\n",
              "      <td>0.159673</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053792</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>0.021713</td>\n",
              "      <td>-0.040749</td>\n",
              "      <td>0.232137</td>\n",
              "      <td>-0.021132</td>\n",
              "      <td>-0.026330</td>\n",
              "      <td>0.062515</td>\n",
              "      <td>0.072006</td>\n",
              "      <td>-0.022570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1990814</td>\n",
              "      <td>ML0120ENv3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.039600</td>\n",
              "      <td>0.171552</td>\n",
              "      <td>0.004101</td>\n",
              "      <td>0.035966</td>\n",
              "      <td>-0.149341</td>\n",
              "      <td>-0.000231</td>\n",
              "      <td>-0.165297</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.047942</td>\n",
              "      <td>-0.057169</td>\n",
              "      <td>0.124602</td>\n",
              "      <td>-0.197989</td>\n",
              "      <td>-0.107890</td>\n",
              "      <td>-0.111450</td>\n",
              "      <td>-0.114045</td>\n",
              "      <td>0.058036</td>\n",
              "      <td>-0.199624</td>\n",
              "      <td>0.259155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>380098</td>\n",
              "      <td>BD0211EN</td>\n",
              "      <td>5</td>\n",
              "      <td>0.120070</td>\n",
              "      <td>-0.198679</td>\n",
              "      <td>0.034901</td>\n",
              "      <td>-0.085777</td>\n",
              "      <td>-0.020262</td>\n",
              "      <td>0.233966</td>\n",
              "      <td>-0.125914</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027686</td>\n",
              "      <td>0.116564</td>\n",
              "      <td>0.025722</td>\n",
              "      <td>0.001413</td>\n",
              "      <td>0.140056</td>\n",
              "      <td>-0.036409</td>\n",
              "      <td>-0.062878</td>\n",
              "      <td>0.033082</td>\n",
              "      <td>0.042508</td>\n",
              "      <td>-0.130935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>779563</td>\n",
              "      <td>DS0101EN</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.030299</td>\n",
              "      <td>0.059425</td>\n",
              "      <td>-0.089233</td>\n",
              "      <td>-0.037715</td>\n",
              "      <td>0.066093</td>\n",
              "      <td>-0.045554</td>\n",
              "      <td>0.048373</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005192</td>\n",
              "      <td>0.013957</td>\n",
              "      <td>-0.095489</td>\n",
              "      <td>0.006763</td>\n",
              "      <td>-0.055791</td>\n",
              "      <td>0.034223</td>\n",
              "      <td>-0.041170</td>\n",
              "      <td>0.082775</td>\n",
              "      <td>-0.108192</td>\n",
              "      <td>0.064673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 63 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      user        item  rating       0_x       1_x       2_x       3_x  \\\n",
              "0  1889878    CC0101EN       5 -0.106539  0.169725  0.037759 -0.179715   \n",
              "1  1342067    CL0101EN       3  0.043064  0.014002  0.107306  0.064301   \n",
              "2  1990814  ML0120ENv3       5  0.039600  0.171552  0.004101  0.035966   \n",
              "3   380098    BD0211EN       5  0.120070 -0.198679  0.034901 -0.085777   \n",
              "4   779563    DS0101EN       3 -0.030299  0.059425 -0.089233 -0.037715   \n",
              "\n",
              "        4_x       5_x       6_x  ...      20_y      21_y      22_y      23_y  \\\n",
              "0  0.004930 -0.025669 -0.081321  ... -0.073589 -0.003626  0.015632 -0.010677   \n",
              "1  0.106295 -0.053030  0.159673  ... -0.053792  0.000152  0.021713 -0.040749   \n",
              "2 -0.149341 -0.000231 -0.165297  ... -0.047942 -0.057169  0.124602 -0.197989   \n",
              "3 -0.020262  0.233966 -0.125914  ... -0.027686  0.116564  0.025722  0.001413   \n",
              "4  0.066093 -0.045554  0.048373  ...  0.005192  0.013957 -0.095489  0.006763   \n",
              "\n",
              "       24_y      25_y      26_y      27_y      28_y      29_y  \n",
              "0 -0.073484 -0.097091 -0.072879 -0.110306  0.079633 -0.084364  \n",
              "1  0.232137 -0.021132 -0.026330  0.062515  0.072006 -0.022570  \n",
              "2 -0.107890 -0.111450 -0.114045  0.058036 -0.199624  0.259155  \n",
              "3  0.140056 -0.036409 -0.062878  0.033082  0.042508 -0.130935  \n",
              "4 -0.055791  0.034223 -0.041170  0.082775 -0.108192  0.064673  \n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rating_df_2 = rating_df.copy()\n",
        "\n",
        "df_2 = pd.merge(rating_df_2,user_latent_df, how='left', on='user').fillna(0)\n",
        "df_3 = pd.merge(df_2, item_latent_df, how='left', on='item').fillna(0)\n",
        "df_3.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we can combine the user features (the column labels with `_x`) and item features (the column labels with `_y`). In machine learning, there are many ways to aggregate two feature vectors such as element-wise add, multiply, max/min, average, etc. Here we simply add the two sets of feature columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "ufeature = df_3.iloc[:,3+embedding_size:].values\n",
        "ifeature = df_3.iloc[:,3:3+embedding_size].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>item</th>\n",
              "      <th>rating</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>...</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1889878</td>\n",
              "      <td>CC0101EN</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.122779</td>\n",
              "      <td>0.066674</td>\n",
              "      <td>0.045154</td>\n",
              "      <td>-0.124728</td>\n",
              "      <td>0.059997</td>\n",
              "      <td>-0.019662</td>\n",
              "      <td>-0.123634</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.116998</td>\n",
              "      <td>0.043467</td>\n",
              "      <td>-0.243266</td>\n",
              "      <td>-0.054577</td>\n",
              "      <td>-0.069745</td>\n",
              "      <td>0.100810</td>\n",
              "      <td>0.079515</td>\n",
              "      <td>-0.086147</td>\n",
              "      <td>0.265758</td>\n",
              "      <td>-0.101739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1342067</td>\n",
              "      <td>CL0101EN</td>\n",
              "      <td>3</td>\n",
              "      <td>0.016062</td>\n",
              "      <td>-0.072741</td>\n",
              "      <td>0.178477</td>\n",
              "      <td>0.056657</td>\n",
              "      <td>0.181673</td>\n",
              "      <td>0.136927</td>\n",
              "      <td>0.219265</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.206626</td>\n",
              "      <td>-0.001898</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>0.026444</td>\n",
              "      <td>0.308114</td>\n",
              "      <td>-0.076159</td>\n",
              "      <td>0.032171</td>\n",
              "      <td>0.054934</td>\n",
              "      <td>-0.095736</td>\n",
              "      <td>0.029776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1990814</td>\n",
              "      <td>ML0120ENv3</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.064243</td>\n",
              "      <td>0.388992</td>\n",
              "      <td>0.180984</td>\n",
              "      <td>0.094553</td>\n",
              "      <td>-0.186661</td>\n",
              "      <td>0.041670</td>\n",
              "      <td>-0.055650</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.248554</td>\n",
              "      <td>0.103933</td>\n",
              "      <td>0.149265</td>\n",
              "      <td>-0.128934</td>\n",
              "      <td>-0.174402</td>\n",
              "      <td>-0.082286</td>\n",
              "      <td>-0.087159</td>\n",
              "      <td>0.206683</td>\n",
              "      <td>-0.102751</td>\n",
              "      <td>0.303564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>380098</td>\n",
              "      <td>BD0211EN</td>\n",
              "      <td>5</td>\n",
              "      <td>0.072817</td>\n",
              "      <td>-0.234047</td>\n",
              "      <td>-0.043238</td>\n",
              "      <td>-0.085615</td>\n",
              "      <td>0.013083</td>\n",
              "      <td>0.196668</td>\n",
              "      <td>-0.116750</td>\n",
              "      <td>...</td>\n",
              "      <td>0.293288</td>\n",
              "      <td>-0.033597</td>\n",
              "      <td>0.102955</td>\n",
              "      <td>-0.053723</td>\n",
              "      <td>0.133037</td>\n",
              "      <td>0.028790</td>\n",
              "      <td>0.096798</td>\n",
              "      <td>-0.068260</td>\n",
              "      <td>-0.112052</td>\n",
              "      <td>-0.033939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>779563</td>\n",
              "      <td>DS0101EN</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.080839</td>\n",
              "      <td>0.116727</td>\n",
              "      <td>-0.144671</td>\n",
              "      <td>-0.064000</td>\n",
              "      <td>0.013647</td>\n",
              "      <td>-0.092487</td>\n",
              "      <td>0.082701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035115</td>\n",
              "      <td>0.027344</td>\n",
              "      <td>-0.024726</td>\n",
              "      <td>0.054824</td>\n",
              "      <td>-0.073673</td>\n",
              "      <td>0.152961</td>\n",
              "      <td>-0.052597</td>\n",
              "      <td>-0.042063</td>\n",
              "      <td>-0.118212</td>\n",
              "      <td>0.145725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      user        item  rating         0         1         2         3  \\\n",
              "0  1889878    CC0101EN       5 -0.122779  0.066674  0.045154 -0.124728   \n",
              "1  1342067    CL0101EN       3  0.016062 -0.072741  0.178477  0.056657   \n",
              "2  1990814  ML0120ENv3       5 -0.064243  0.388992  0.180984  0.094553   \n",
              "3   380098    BD0211EN       5  0.072817 -0.234047 -0.043238 -0.085615   \n",
              "4   779563    DS0101EN       3 -0.080839  0.116727 -0.144671 -0.064000   \n",
              "\n",
              "          4         5         6  ...        20        21        22        23  \\\n",
              "0  0.059997 -0.019662 -0.123634  ... -0.116998  0.043467 -0.243266 -0.054577   \n",
              "1  0.181673  0.136927  0.219265  ... -0.206626 -0.001898 -0.037344  0.026444   \n",
              "2 -0.186661  0.041670 -0.055650  ... -0.248554  0.103933  0.149265 -0.128934   \n",
              "3  0.013083  0.196668 -0.116750  ...  0.293288 -0.033597  0.102955 -0.053723   \n",
              "4  0.013647 -0.092487  0.082701  ...  0.035115  0.027344 -0.024726  0.054824   \n",
              "\n",
              "         24        25        26        27        28        29  \n",
              "0 -0.069745  0.100810  0.079515 -0.086147  0.265758 -0.101739  \n",
              "1  0.308114 -0.076159  0.032171  0.054934 -0.095736  0.029776  \n",
              "2 -0.174402 -0.082286 -0.087159  0.206683 -0.102751  0.303564  \n",
              "3  0.133037  0.028790  0.096798 -0.068260 -0.112052 -0.033939  \n",
              "4 -0.073673  0.152961 -0.052597 -0.042063 -0.118212  0.145725  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summ_UI = ufeature + ifeature\n",
        "features_df = pd.concat([df_3[['user','item','rating']], pd.DataFrame(data=summ_UI)],axis=1)\n",
        "features_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define new training and test sets for linear regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_features = features_df.iloc[:,3:]\n",
        "y_features = features_df.iloc[:,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_features, y_features, test_size=0.2, random_state = rs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Linear Regrassion (Ridge) on predicted rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "Ridge()"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a Linear regression model with above arguments\n",
        "linear_regressor = Ridge()\n",
        "linear_regressor.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test root_mean_squared_error for linear regression is 0.82\n"
          ]
        }
      ],
      "source": [
        "regressor_predict = linear_regressor.predict(x_test)\n",
        "regressor_score = math.sqrt( mean_squared_error(y_test, regressor_predict) )\n",
        "\n",
        "print(f\"Test root_mean_squared_error for linear regression is {round(regressor_score, 2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `RMSE` for linear regression is very similar to **KNN** and **NMF** models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "prev_pub_hash": "b666e2b2e913b0897482548eb096a4e157b670ab86270b1b3a78e523a1f244d9"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
